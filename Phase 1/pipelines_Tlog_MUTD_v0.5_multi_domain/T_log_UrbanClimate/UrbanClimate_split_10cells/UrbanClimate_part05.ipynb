{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b71a7e",
   "metadata": {
    "id": "Fddi9sS_eGnJ"
   },
   "source": [
    "Cellule Python — diagnostics détaillés par fenêtre et heatmap par ville\n",
    "\n",
    " La cellule :\n",
    "\n",
    "lit l’index enrichi results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_windows_index_enriched.csv ;\n",
    "\n",
    "pour chaque fenêtre exporte un CSV diagnostics détaillés par feature (skew, median, mean, std, frac_NaN, top-3 valeurs extrêmes) et un CSV résumé par ville ;\n",
    "\n",
    "crée un heatmap (cities × features numériques) sauvegardé en PNG (z-score ou min-max normalisé selon disponibilité) ;\n",
    "\n",
    "sauvegarde les sorties dans results/temporal_cv_atypical_windows/diagnostics/<window_tag>/ et écrit des entrées de log dans logs/summary.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "969fb10f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26309,
     "status": "ok",
     "timestamp": 1761431063382,
     "user": {
      "displayName": "GlobalZivotPrint",
      "userId": "12055292741917834281"
     },
     "user_tz": 240
    },
    "id": "GS0wlIZfeJtK",
    "outputId": "09c4fe1f-0908-4023-bf2e-7df183c3919d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for 3yr_1984.0_A: results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_A\\diagnostics_features_3yr_1984.0_A.csv, results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_A\\diagnostics_by_city_3yr_1984.0_A.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_A\\heatmap_cities_features_3yr_1984.0_A.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for 3yr_1984.0_B: results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_B\\diagnostics_features_3yr_1984.0_B.csv, results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_B\\diagnostics_by_city_3yr_1984.0_B.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_B\\heatmap_cities_features_3yr_1984.0_B.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for 3yr_1984.0_C: results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_C\\diagnostics_features_3yr_1984.0_C.csv, results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_C\\diagnostics_by_city_3yr_1984.0_C.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\3yr_1984.0_C\\heatmap_cities_features_3yr_1984.0_C.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for 3yr_2014.0_A: results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_A\\diagnostics_features_3yr_2014.0_A.csv, results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_A\\diagnostics_by_city_3yr_2014.0_A.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_A\\heatmap_cities_features_3yr_2014.0_A.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for 3yr_2014.0_B: results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_B\\diagnostics_features_3yr_2014.0_B.csv, results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_B\\diagnostics_by_city_3yr_2014.0_B.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_B\\heatmap_cities_features_3yr_2014.0_B.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for 3yr_2014.0_C: results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_C\\diagnostics_features_3yr_2014.0_C.csv, results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_C\\diagnostics_by_city_3yr_2014.0_C.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\3yr_2014.0_C\\heatmap_cities_features_3yr_2014.0_C.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2003.0_A: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2003.0_A\\diagnostics_features_annual_2003.0_A.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2003.0_A\\diagnostics_by_city_annual_2003.0_A.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2003.0_A\\heatmap_cities_features_annual_2003.0_A.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2003.0_C: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2003.0_C\\diagnostics_features_annual_2003.0_C.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2003.0_C\\diagnostics_by_city_annual_2003.0_C.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2003.0_C\\heatmap_cities_features_annual_2003.0_C.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2008.0_A: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_A\\diagnostics_features_annual_2008.0_A.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_A\\diagnostics_by_city_annual_2008.0_A.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_A\\heatmap_cities_features_annual_2008.0_A.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2008.0_B: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_B\\diagnostics_features_annual_2008.0_B.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_B\\diagnostics_by_city_annual_2008.0_B.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_B\\heatmap_cities_features_annual_2008.0_B.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2008.0_C: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_C\\diagnostics_features_annual_2008.0_C.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_C\\diagnostics_by_city_annual_2008.0_C.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2008.0_C\\heatmap_cities_features_annual_2008.0_C.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2012.0_A: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_A\\diagnostics_features_annual_2012.0_A.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_A\\diagnostics_by_city_annual_2012.0_A.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_A\\heatmap_cities_features_annual_2012.0_A.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2012.0_B: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_B\\diagnostics_features_annual_2012.0_B.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_B\\diagnostics_by_city_annual_2012.0_B.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_B\\heatmap_cities_features_annual_2012.0_B.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2012.0_C: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_C\\diagnostics_features_annual_2012.0_C.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_C\\diagnostics_by_city_annual_2012.0_C.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2012.0_C\\heatmap_cities_features_annual_2012.0_C.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2014.0_A: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2014.0_A\\diagnostics_features_annual_2014.0_A.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2014.0_A\\diagnostics_by_city_annual_2014.0_A.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2014.0_A\\heatmap_cities_features_annual_2014.0_A.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2014.0_C: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2014.0_C\\diagnostics_features_annual_2014.0_C.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2014.0_C\\diagnostics_by_city_annual_2014.0_C.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2014.0_C\\heatmap_cities_features_annual_2014.0_C.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2016.0_A: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_A\\diagnostics_features_annual_2016.0_A.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_A\\diagnostics_by_city_annual_2016.0_A.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_A\\heatmap_cities_features_annual_2016.0_A.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diagnostics for annual_2016.0_B: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_B\\diagnostics_features_annual_2016.0_B.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_B\\diagnostics_by_city_annual_2016.0_B.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_B\\heatmap_cities_features_annual_2016.0_B.png\n",
      "Wrote diagnostics for annual_2016.0_C: results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_C\\diagnostics_features_annual_2016.0_C.csv, results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_C\\diagnostics_by_city_annual_2016.0_C.csv, heatmap=results\\temporal_cv_atypical_windows\\diagnostics\\annual_2016.0_C\\heatmap_cities_features_annual_2016.0_C.png\n",
      "All diagnostics completed. Outputs under: results\\temporal_cv_atypical_windows\\diagnostics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:175: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
      "C:\\Users\\zackd\\AppData\\Local\\Temp\\ipykernel_5596\\3763337873.py:22: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics détaillés et heatmaps par fenêtre atypique\n",
    "import os, math, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Config paths\n",
    "BASE_IDX = 'results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_windows_index_enriched.csv'\n",
    "RAW_BASE_DIR = 'results/temporal_cv_atypical_windows'\n",
    "OUT_BASE = os.path.join('results', 'temporal_cv_atypical_windows', 'diagnostics')\n",
    "LOG_SUMMARY = os.path.join('logs', 'summary.md')\n",
    "os.makedirs(OUT_BASE, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(LOG_SUMMARY), exist_ok=True)\n",
    "\n",
    "def safe_tag(s):\n",
    "    return re.sub(r'[^0-9A-Za-z_.-]', '_', str(s))\n",
    "\n",
    "def append_log(msg):\n",
    "    ts = datetime.utcnow().isoformat() + 'Z'\n",
    "    with open(LOG_SUMMARY, 'a', encoding='utf-8') as f:\n",
    "        f.write(f'- {ts} INFO: {msg}\\n')\n",
    "\n",
    "if not os.path.exists(BASE_IDX):\n",
    "    raise FileNotFoundError(f'Index enriched introuvable: {BASE_IDX}')\n",
    "\n",
    "idx = pd.read_csv(BASE_IDX)\n",
    "\n",
    "# Columns to prefer for features\n",
    "PREFERRED_NUMERIC = ['temperature_celsius','humidity_percent','precipitation_mm','wind_speed_ms','urban_heat_island_intensity']\n",
    "\n",
    "for _, entry in idx.iterrows():\n",
    "    try:\n",
    "        raw_fp = entry['raw_csv']\n",
    "        if not isinstance(raw_fp, str) or not raw_fp or not os.path.exists(raw_fp):\n",
    "            append_log(f\"Skipping missing raw file for entry: {entry.get('pipeline','?')} {entry.get('window_center','?')}\")\n",
    "            continue\n",
    "\n",
    "        # Build output folder for this window\n",
    "        wtype = entry.get('window_type','unknown')\n",
    "        wc = entry.get('window_center','nan')\n",
    "        pipeline = entry.get('pipeline','X')\n",
    "        tag = safe_tag(f\"{wtype}_{wc}_{pipeline}\")\n",
    "        out_dir = os.path.join(OUT_BASE, tag)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # Read raw data\n",
    "        df = pd.read_csv(raw_fp)\n",
    "        if df.empty:\n",
    "            append_log(f\"No rows in raw file {raw_fp}, skipped.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure city_key\n",
    "        if 'city_key' not in df.columns:\n",
    "            agg_cols = [c for c in ['city','country','latitude','longitude'] if c in df.columns]\n",
    "            if agg_cols:\n",
    "                df['city_key'] = df[agg_cols].astype(str).agg('_'.join, axis=1)\n",
    "            else:\n",
    "                df['city_key'] = 'unknown'\n",
    "\n",
    "        # Determine numeric feature columns\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        # remove control columns\n",
    "        numeric_cols = [c for c in numeric_cols if c not in ['year','month','ym','n_rows']]\n",
    "        # prioritize preferred set if present\n",
    "        pref_present = [c for c in PREFERRED_NUMERIC if c in numeric_cols]\n",
    "        if pref_present:\n",
    "            features = pref_present\n",
    "        else:\n",
    "            # fallback: top numeric columns by variance\n",
    "            if numeric_cols:\n",
    "                variances = df[numeric_cols].var(numeric_only=True).sort_values(ascending=False)\n",
    "                features = variances.index.tolist()[:min(10, len(variances))]\n",
    "            else:\n",
    "                features = []\n",
    "\n",
    "        # Prepare diagnostics per feature\n",
    "        diag_rows = []\n",
    "        for feat in features:\n",
    "            col = df[feat]\n",
    "            n = col.shape[0]\n",
    "            n_nan = int(col.isna().sum())\n",
    "            frac_nan = float(n_nan)/max(1,n)\n",
    "            valid = col.dropna().astype(float)\n",
    "            if valid.empty:\n",
    "                median_v = np.nan\n",
    "                mean_v = np.nan\n",
    "                std_v = np.nan\n",
    "                skew_v = np.nan\n",
    "                top3 = []\n",
    "                bottom3 = []\n",
    "            else:\n",
    "                median_v = float(valid.median())\n",
    "                mean_v = float(valid.mean())\n",
    "                std_v = float(valid.std(ddof=1))\n",
    "                try:\n",
    "                    skew_v = float(skew(valid))\n",
    "                except Exception:\n",
    "                    skew_v = np.nan\n",
    "                # top-3 extremes (largest absolute deviation from median)\n",
    "                dev = (valid - median_v).abs()\n",
    "                top3_idx = dev.sort_values(ascending=False).head(3).index\n",
    "                top3 = [(int(i), float(valid.loc[i])) for i in top3_idx]\n",
    "                bottom3 = [(int(i), float(valid.loc[i])) for i in valid.sort_values().head(3).index]\n",
    "            diag_rows.append({\n",
    "                'feature': feat,\n",
    "                'n': n,\n",
    "                'n_nan': n_nan,\n",
    "                'frac_nan': frac_nan,\n",
    "                'mean': mean_v,\n",
    "                'median': median_v,\n",
    "                'std': std_v,\n",
    "                'skew': skew_v,\n",
    "                'top3_idx_val': ';'.join([f\"{i}:{v}\" for i,v in top3]),\n",
    "                'bottom3_idx_val': ';'.join([f\"{i}:{v}\" for i,v in bottom3])\n",
    "            })\n",
    "        diag_df = pd.DataFrame(diag_rows)\n",
    "        diag_csv = os.path.join(out_dir, f'diagnostics_features_{tag}.csv')\n",
    "        diag_df.to_csv(diag_csv, index=False)\n",
    "\n",
    "        # Per-city summary (n_obs, medians per feature)\n",
    "        group = df.groupby('city_key')\n",
    "        city_rows = []\n",
    "        for city, g in group:\n",
    "            row = {'city_key': city, 'n_obs': int(g.shape[0])}\n",
    "            for feat in features:\n",
    "                try:\n",
    "                    row[f'median_{feat}'] = float(g[feat].median()) if feat in g.columns else np.nan\n",
    "                    row[f'mean_{feat}'] = float(g[feat].mean()) if feat in g.columns else np.nan\n",
    "                    row[f'frac_nan_{feat}'] = float(g[feat].isna().sum())/max(1, g.shape[0]) if feat in g.columns else np.nan\n",
    "                except Exception:\n",
    "                    row[f'median_{feat}'] = np.nan\n",
    "                    row[f'mean_{feat}'] = np.nan\n",
    "                    row[f'frac_nan_{feat}'] = np.nan\n",
    "            city_rows.append(row)\n",
    "        city_df = pd.DataFrame(city_rows).sort_values('n_obs', ascending=False)\n",
    "        city_csv = os.path.join(out_dir, f'diagnostics_by_city_{tag}.csv')\n",
    "        city_df.to_csv(city_csv, index=False)\n",
    "\n",
    "        # Heatmap matrix: rows = cities (sorted), cols = features; use median per city (or mean)\n",
    "        if features:\n",
    "            heat_mat = city_df.set_index('city_key')[[f'median_{f}' for f in features]].replace([np.inf, -np.inf], np.nan)\n",
    "            # If many cities, limit display order to top N by n_obs (but keep all saved)\n",
    "            # Normalize for display: z-score per feature if possible, fallback to min-max\n",
    "            heat = heat_mat.copy().astype(float)\n",
    "            # compute zscore per column where std>0\n",
    "            for col in heat.columns:\n",
    "                col_vals = heat[col]\n",
    "                if col_vals.dropna().shape[0] >= 2 and not np.isclose(col_vals.std(ddof=1), 0.0):\n",
    "                    heat[col] = (col_vals - col_vals.mean()) / col_vals.std(ddof=1)\n",
    "                else:\n",
    "                    mn = col_vals.min()\n",
    "                    mx = col_vals.max()\n",
    "                    if pd.isna(mn) or pd.isna(mx) or np.isclose(mx, mn):\n",
    "                        heat[col] = 0.0\n",
    "                    else:\n",
    "                        heat[col] = (col_vals - mn) / (mx - mn)\n",
    "            # Plot heatmap\n",
    "            plt.figure(figsize=(max(6, min(14, heat.shape[1])), max(6, min(30, heat.shape[0]*0.4))))\n",
    "            sns.heatmap(heat, cmap='vlag', center=0, cbar_kws={'label':'normalized value'}, linewidths=0.25)\n",
    "            plt.title(f'Heatmap medians per city - {tag}')\n",
    "            plt.tight_layout()\n",
    "            heat_png = os.path.join(out_dir, f'heatmap_cities_features_{tag}.png')\n",
    "            plt.savefig(heat_png, dpi=200)\n",
    "            plt.close()\n",
    "        else:\n",
    "            heat_png = None\n",
    "\n",
    "        # Short summary markdown\n",
    "        md_fp = os.path.join(out_dir, f'summary_{tag}.md')\n",
    "        with open(md_fp, 'w', encoding='utf-8') as f:\n",
    "            f.write(f'# Diagnostics pour fenêtre {tag}\\n\\n')\n",
    "            f.write(f'Generated: {datetime.utcnow().isoformat()}Z\\n\\n')\n",
    "            f.write(f'- raw file: {raw_fp}\\n')\n",
    "            f.write(f'- features used ({len(features)}): {features}\\n')\n",
    "            f.write(f'- diagnostics features CSV: {os.path.basename(diag_csv)}\\n')\n",
    "            f.write(f'- per-city CSV: {os.path.basename(city_csv)}\\n')\n",
    "            if heat_png:\n",
    "                f.write(f'- heatmap: {os.path.basename(heat_png)}\\n')\n",
    "            else:\n",
    "                f.write('- heatmap: none (no numeric features)\\n')\n",
    "            f.write('\\n## Observations rapides\\n\\n')\n",
    "            # add a tiny textual top3 for each feature\n",
    "            for rid, r in diag_df.iterrows():\n",
    "                f.write(f\"- **{r['feature']}**: n={int(r['n'])}; frac_NaN={r['frac_nan']:.3f}; median={r['median']}; mean={r['mean']}; skew={r['skew']}\\n\")\n",
    "            f.write('\\n')\n",
    "        append_log(f'Produced diagnostics for window {tag} -> {out_dir} (rows={df.shape[0]}, features={len(features)})')\n",
    "        print(f'Wrote diagnostics for {tag}: {diag_csv}, {city_csv}, heatmap={heat_png}')\n",
    "    except Exception as e:\n",
    "        append_log(f'Error processing entry {entry.get(\"pipeline\",\"?\")} {entry.get(\"window_center\",\"?\")}: {e}')\n",
    "        print('Error for entry:', entry.get('window_center','?'), entry.get('pipeline','?'), e)\n",
    "\n",
    "print('All diagnostics completed. Outputs under:', OUT_BASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556dc44",
   "metadata": {
    "id": "ma_limwbiGzx"
   },
   "source": [
    "Cellule Python — créer un fichier résumé compact + package des fichiers clés à envoyer\n",
    "\n",
    "La cellule :\n",
    "\n",
    "parcourt les diagnostics déjà produits sous results/temporal_cv_atypical_windows/diagnostics ;\n",
    "\n",
    "construit un CSV résumé compact par fenêtre (one‑row per window) avec : window_type, window_center, pipeline, n_rows, prop_obs_outlier, median_md, prop_cities_with_gt10pct_outliers, max_city_outlier_frac, flag_for_review, top3_cities_by_outlier_frac, features_used, path_summary_md, path_heatmap, path_by_city_csv ;\n",
    "\n",
    "crée un ZIP contenant pour chaque fenêtre les trois fichiers essentiels (summary markdown, by_city CSV, heatmap PNG quand présents) afin que vous puissiez m’envoyer un seul fichier compressé;\n",
    "\n",
    "écrit le CSV résumé results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_summary.csv et le package results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_summary_package.zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd4ecacb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1761432087303,
     "user": {
      "displayName": "GlobalZivotPrint",
      "userId": "12055292741917834281"
     },
     "user_tz": 240
    },
    "id": "5q4dyDqJiKBP",
    "outputId": "5f64cce4-a689-4b76-d2c4-1a6b75abd208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résumé CSV écrit : results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_summary.csv\n",
      "Package ZIP écrit : results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_summary_package.zip\n",
      "Fichiers inclus dans le package: 57 (exemple 10):\n",
      "['results/temporal_cv_atypical_windows/diagnostics\\\\3yr_1984.0_A\\\\summary_3yr_1984.0_A.md', 'results/temporal_cv_atypical_windows/diagnostics\\\\3yr_1984.0_A\\\\heatmap_cities_features_3yr_1984.0_A.png', 'results\\\\temporal_cv_atypical_windows\\\\temporal_cv_atypical_period_window_3yr_1984.00_A_raw.csv', 'results/temporal_cv_atypical_windows/diagnostics\\\\3yr_1984.0_B\\\\summary_3yr_1984.0_B.md', 'results/temporal_cv_atypical_windows/diagnostics\\\\3yr_1984.0_B\\\\heatmap_cities_features_3yr_1984.0_B.png', 'results\\\\temporal_cv_atypical_windows\\\\temporal_cv_atypical_period_window_3yr_1984.00_B_raw.csv', 'results/temporal_cv_atypical_windows/diagnostics\\\\3yr_1984.0_C\\\\summary_3yr_1984.0_C.md', 'results/temporal_cv_atypical_windows/diagnostics\\\\3yr_1984.0_C\\\\heatmap_cities_features_3yr_1984.0_C.png', 'results\\\\temporal_cv_atypical_windows\\\\temporal_cv_atypical_period_window_3yr_1984.00_C_raw.csv', 'results/temporal_cv_atypical_windows/diagnostics\\\\3yr_2014.0_A\\\\summary_3yr_2014.0_A.md']\n"
     ]
    }
   ],
   "source": [
    "# Création d'un résumé compact et package ZIP des fichiers clés à envoyer\n",
    "import os, glob, zipfile, json, re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "BASE_IDX_ENR = 'results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_windows_index_enriched.csv'\n",
    "DIAG_BASE = 'results/temporal_cv_atypical_windows/diagnostics'\n",
    "OUT_SUMMARY_CSV = 'results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_summary.csv'\n",
    "OUT_ZIP = 'results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_summary_package.zip'\n",
    "\n",
    "def safe_tag(s):\n",
    "    return re.sub(r'[^0-9A-Za-z_.-]', '_', str(s))\n",
    "\n",
    "if not os.path.exists(BASE_IDX_ENR):\n",
    "    raise FileNotFoundError(f'Fichier d’index enrichi introuvable: {BASE_IDX_ENR}')\n",
    "\n",
    "idx = pd.read_csv(BASE_IDX_ENR)\n",
    "\n",
    "rows = []\n",
    "files_to_package = []\n",
    "\n",
    "for _, r in idx.iterrows():\n",
    "    wtype = r.get('window_type')\n",
    "    wc = r.get('window_center')\n",
    "    pipeline = r.get('pipeline')\n",
    "    tag = safe_tag(f\"{wtype}_{wc}_{pipeline}\")\n",
    "    diag_dir = os.path.join(DIAG_BASE, tag)\n",
    "    # locate expected artifacts\n",
    "    summary_md = glob.glob(os.path.join(diag_dir, f\"summary_{tag}.md\"))\n",
    "    heatmap = glob.glob(os.path.join(diag_dir, f\"heatmap_cities_features_{tag}.png\"))\n",
    "    by_city_candidates = glob.glob(os.path.join('results','temporal_cv_atypical_windows',f\"*{tag}*_by_city.csv\"))\n",
    "    # choose paths or None\n",
    "    summary_md_p = summary_md[0] if summary_md else None\n",
    "    heatmap_p = heatmap[0] if heatmap else None\n",
    "    by_city_p = by_city_candidates[0] if by_city_candidates else None\n",
    "    # compute top3 cities by outlier frac if by_city available\n",
    "    top3_cities = []\n",
    "    if by_city_p and os.path.exists(by_city_p):\n",
    "        try:\n",
    "            bc = pd.read_csv(by_city_p)\n",
    "            # detect columns that may indicate outlier fraction per city (looks for 'frac' or 'outlier')\n",
    "            frac_cols = [c for c in bc.columns if 'outlier' in c.lower() or 'frac' in c.lower()]\n",
    "            # fallback: use n_obs to rank\n",
    "            if frac_cols:\n",
    "                # use first frac column\n",
    "                col = frac_cols[0]\n",
    "                top3 = bc.sort_values(col, ascending=False).head(3)\n",
    "                top3_cities = [f\"{row['city_key']}:{row[col]:.3f}\" for _, row in top3.iterrows()]\n",
    "            else:\n",
    "                top3 = bc.sort_values('n_obs', ascending=False).head(3)\n",
    "                top3_cities = [f\"{row['city_key']}:nobs={int(row['n_obs'])}\" for _, row in top3.iterrows()]\n",
    "        except Exception:\n",
    "            top3_cities = []\n",
    "    # features used: try to read diagnostics_features file\n",
    "    feat_file = glob.glob(os.path.join(diag_dir, f\"diagnostics_features_{tag}.csv\"))\n",
    "    features_used = None\n",
    "    if feat_file:\n",
    "        try:\n",
    "            df_feat = pd.read_csv(feat_file[0])\n",
    "            features_used = ';'.join(df_feat['feature'].astype(str).tolist())\n",
    "        except Exception:\n",
    "            features_used = None\n",
    "\n",
    "    row = {\n",
    "        'window_type': wtype,\n",
    "        'window_center': wc,\n",
    "        'pipeline': pipeline,\n",
    "        'n_rows': int(r.get('n_rows', 0)) if not pd.isna(r.get('n_rows', None)) else None,\n",
    "        'prop_obs_outlier': r.get('prop_obs_outlier'),\n",
    "        'median_md': r.get('median_md'),\n",
    "        'prop_cities_with_gt10pct_outliers': r.get('prop_cities_with_gt10pct_outliers'),\n",
    "        'max_city_outlier_frac': r.get('max_city_outlier_frac'),\n",
    "        'flag_for_review': bool(r.get('flag_for_review', False)),\n",
    "        'top3_cities_by_outlier_or_nobs': ';'.join(top3_cities),\n",
    "        'features_used': features_used,\n",
    "        'path_summary_md': summary_md_p,\n",
    "        'path_heatmap_png': heatmap_p,\n",
    "        'path_by_city_csv': by_city_p\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "    # add files to package if exist (one set per window)\n",
    "    to_add = []\n",
    "    if row['path_summary_md']:\n",
    "        to_add.append(row['path_summary_md'])\n",
    "    if row['path_by_city_csv']:\n",
    "        to_add.append(row['path_by_city_csv'])\n",
    "    if row['path_heatmap_png']:\n",
    "        to_add.append(row['path_heatmap_png'])\n",
    "    # add raw index entry and raw CSV referenced in base index as well\n",
    "    if 'raw_csv' in r and isinstance(r['raw_csv'], str) and os.path.exists(r['raw_csv']):\n",
    "        to_add.append(r['raw_csv'])\n",
    "    # deduplicate and extend files_to_package\n",
    "    for p in to_add:\n",
    "        if p and p not in files_to_package:\n",
    "            files_to_package.append(p)\n",
    "\n",
    "# create summary dataframe and save CSV\n",
    "summary_df = pd.DataFrame(rows)\n",
    "os.makedirs(os.path.dirname(OUT_SUMMARY_CSV), exist_ok=True)\n",
    "summary_df.to_csv(OUT_SUMMARY_CSV, index=False)\n",
    "\n",
    "# package files into zip\n",
    "if files_to_package:\n",
    "    with zipfile.ZipFile(OUT_ZIP, 'w', compression=zipfile.ZIP_DEFLATED) as z:\n",
    "        for fp in files_to_package:\n",
    "            arcname = os.path.join('atypical_windows_files', os.path.basename(fp))\n",
    "            try:\n",
    "                z.write(fp, arcname=arcname)\n",
    "            except Exception:\n",
    "                # skip files that cannot be read\n",
    "                pass\n",
    "\n",
    "print(\"Résumé CSV écrit :\", OUT_SUMMARY_CSV)\n",
    "print(\"Package ZIP écrit :\", OUT_ZIP)\n",
    "print(f\"Fichiers inclus dans le package: {len(files_to_package)} (exemple 10):\")\n",
    "print(files_to_package[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ef9c0",
   "metadata": {
    "id": "ZeueYMlrrHf5"
   },
   "source": [
    "Liste prioritaire détaillée — Pipeline A (A_baseline_StandardScaler)\n",
    "Fichiers clés et intégrité\n",
    "\n",
    "Vérifier : existence et lecture de results/pipeline_details/A_baseline_StandardScaler_d_estimate.csv, _loo.csv, _loo_summary.csv et results/tlog_pipelines_overview.csv.\n",
    "\n",
    "Objectif : garantir que la sortie a bien été écrite et qu’elle n’est pas vide.\n",
    "\n",
    "Cohérence des paramètres d_est / n_cities / T_log\n",
    "\n",
    "Vérifier : la ligne dans A_baseline_StandardScaler_d_estimate.csv contient d_part, d_pca90, d_est, n_cities.\n",
    "\n",
    "Critère prioritaire : |d_est_reporté - d_est_calculé_local| < 1e-6; n_cities == 20 (ou valeur attendue).\n",
    "\n",
    "Robustesse LOO\n",
    "\n",
    "Vérifier : existence de A_baseline_StandardScaler_loo.csv; calculer mean(T_log_loo), std et rel_std_pct.\n",
    "\n",
    "Critère : rel_std_pct attendu ≈ 24.36% (tolérance configurable, p.ex.. ±2%), mean attendu ≈ -0.353046 (tolérance configurable).\n",
    "\n",
    "Test statistique p-value\n",
    "\n",
    "Vérifier : valeur tstat / pvalue dans A_baseline_StandardScaler_loo_summary.csv ou recomputer t-test; p-value << 0 indique rejet H0.\n",
    "\n",
    "Priorité : haut (valide la signification statistique du résultat).\n",
    "\n",
    "Sanitation / NaN / Inf\n",
    "\n",
    "Vérifier : fichiers sanitized présents (results/tlog_d_estimates_sanitized.csv, results/tlog_leave_one_out_sanitized.csv) et absence de NaN/Inf dans colonnes numériques critiques (d_estimate, T_log, n_used).\n",
    "\n",
    "Priorité : critique (évite instabilités downstream).\n",
    "\n",
    "Sweep / Sensibilité\n",
    "\n",
    "Vérifier : existence de results/{A_baseline_StandardScaler}_sweep_summary.csv; résumé fractions match_frac/unstable_frac conforme aux valeurs attendues.\n",
    "\n",
    "Objectif : assurer comportement stable sous sous-échantillonnage.\n",
    "\n",
    "Temporal CV / Fenêtres atypiques\n",
    "\n",
    "Vérifier : si temporal CV a exporté fenêtres atypiques listées dans temporal_cv_atypical_periods.csv et index enriched.\n",
    "\n",
    "Priorité : moyen (confirme export diagnostic pour revue).\n",
    "\n",
    "Diagnostics features et qualité\n",
    "\n",
    "Vérifier : existence de results/feature_quality_stats.csv et résultats d’outliers (feature_outliers_detected.csv).\n",
    "\n",
    "Objectif : garantir que les features utilisées dans le calcul d sont saines.\n",
    "\n",
    "Reproductibilité minimale\n",
    "\n",
    "Vérifier : existence de results/params.json et README_method.md; exécution idempotente (re-lancer le script bloc 1 ne casse pas les fichiers).\n",
    "\n",
    "Priorité : moyen (audit et traçabilité).\n",
    "\n",
    "Plaque tournante d’alerte (flag review)\n",
    "\n",
    "Vérifier : si windows_index_enriched flag_for_review == True pour fenêtres listées (p.ex. 3yr_1984.0_A).\n",
    "\n",
    "Objectif : signaler les périodes à investiguer manuellement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9b4f4",
   "metadata": {
    "id": "T1JQz6AsrsTI"
   },
   "source": [
    "Remarques rapides\n",
    "\n",
    "Ajustez EXPECTED_N_CITIES et tolérances (TOL_D, TOL_MEAN) selon votre jeu de données ou version de référence.\n",
    "\n",
    "Cette cellule est pensée comme un smoke-test minimal, exécutable immédiatement ; pour audit complet, ajoutez assertions sur distributions des features, comparaison des spectres d’eigenvalues, et tests de reproductibilité (re-run deterministic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a8647ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1761434589763,
     "user": {
      "displayName": "GlobalZivotPrint",
      "userId": "12055292741917834281"
     },
     "user_tz": 240
    },
    "id": "BFTXKj8Trplx",
    "outputId": "7d32ef6c-1b97-41f3-ba2f-52e710a687f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO mean T_log = -0.353046, std = 0.086006, rel_std_pct = 24.36%\n",
      "Recomputed t-test: t=-18.3577, p=1.502880e-13\n",
      "Temporal CV: 19 windows flagged for review\n",
      "\n",
      "All checks passed (minimal pipeline A smoke tests).\n"
     ]
    }
   ],
   "source": [
    "# Cellule de tests rapides pour Pipeline A (A_baseline_StandardScaler)\n",
    "# Execution: coller dans une cellule code et exécuter.\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Configurable\n",
    "TOL_D = 1e-6\n",
    "TOL_MEAN = 1e-3\n",
    "EXPECTED_N_CITIES = 20\n",
    "\n",
    "# Chemins\n",
    "base = \"results/pipeline_details\"\n",
    "f_d = os.path.join(base, \"A_baseline_StandardScaler_d_estimate.csv\")\n",
    "f_loo = os.path.join(base, \"A_baseline_StandardScaler_loo.csv\")\n",
    "f_loo_summary = os.path.join(base, \"A_baseline_StandardScaler_loo_summary.csv\")\n",
    "overview = \"results/tlog_pipelines_overview.csv\"\n",
    "sanitized_summary = \"results/tlog_d_estimates_sanitized.csv\"\n",
    "sanitized_loo = \"results/tlog_leave_one_out_sanitized.csv\"\n",
    "sweep_summary = os.path.join(base, \"A_baseline_StandardScaler_sweep_summary.csv\")\n",
    "temporal_index = \"results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_windows_index_enriched.csv\"\n",
    "\n",
    "errors = []\n",
    "\n",
    "def must_exist(path):\n",
    "    if not os.path.exists(path):\n",
    "        errors.append(f\"MISSING: {path}\")\n",
    "\n",
    "must_exist(f_d)\n",
    "must_exist(f_loo)\n",
    "must_exist(f_loo_summary)\n",
    "must_exist(overview)\n",
    "must_exist(sanitized_summary)\n",
    "must_exist(sanitized_loo)\n",
    "# sweep and temporal index optional but flagged\n",
    "if not os.path.exists(sweep_summary):\n",
    "    print(\"Warning: sweep_summary absent (not fatal for minimal checks)\")\n",
    "if not os.path.exists(temporal_index):\n",
    "    print(\"Warning: temporal_index absent (no atypical window exports found)\")\n",
    "\n",
    "# Read and basic checks\n",
    "if os.path.exists(f_d):\n",
    "    df_d = pd.read_csv(f_d)\n",
    "    if df_d.empty:\n",
    "        errors.append(\"D_EST file empty\")\n",
    "    else:\n",
    "        row = df_d.iloc[-1]\n",
    "        # Expect columns\n",
    "        for col in [\"d_part\",\"d_pca90\",\"d_est\",\"n_cities\",\"T_log\"]:\n",
    "            if col not in df_d.columns:\n",
    "                # some files may not include T_log column; handle gracefully\n",
    "                if col == \"T_log\" and \"T_log\" not in df_d.columns:\n",
    "                    pass\n",
    "                else:\n",
    "                    errors.append(f\"Column missing in d_estimate file: {col}\")\n",
    "        # Consistency: compare with overview if present\n",
    "        if os.path.exists(overview):\n",
    "            ov = pd.read_csv(overview)\n",
    "            row_ov = ov[ov['pipeline'].str.contains(\"A_baseline_StandardScaler\", na=False)]\n",
    "            if not row_ov.empty:\n",
    "                d_est_report = float(row_ov.iloc[0][\"d_est\"])\n",
    "                d_est_file = float(row[\"d_est\"])\n",
    "                if abs(d_est_report - d_est_file) > TOL_D:\n",
    "                    errors.append(f\"d_est mismatch overview vs file: {d_est_report} vs {d_est_file}\")\n",
    "\n",
    "        # n_cities check\n",
    "        n_cities = int(row.get(\"n_cities\", EXPECTED_N_CITIES))\n",
    "        if n_cities != EXPECTED_N_CITIES:\n",
    "            errors.append(f\"n_cities unexpected: {n_cities} (expected {EXPECTED_N_CITIES})\")\n",
    "\n",
    "# LOO checks\n",
    "if os.path.exists(f_loo):\n",
    "    loo = pd.read_csv(f_loo)\n",
    "    if loo.empty:\n",
    "        errors.append(\"LOO file empty\")\n",
    "    else:\n",
    "        if \"T_log\" not in loo.columns:\n",
    "            errors.append(\"LOO missing T_log column\")\n",
    "        else:\n",
    "            meanT = loo[\"T_log\"].mean()\n",
    "            stdT = loo[\"T_log\"].std(ddof=1)\n",
    "            rel_std_pct = (stdT / (abs(meanT) + 1e-12)) * 100.0\n",
    "            print(f\"LOO mean T_log = {meanT:.6f}, std = {stdT:.6f}, rel_std_pct = {rel_std_pct:.2f}%\")\n",
    "            # Compare with expected summary if present\n",
    "            if os.path.exists(f_loo_summary):\n",
    "                summ = pd.read_csv(f_loo_summary)\n",
    "                if \"mean_T_LOO\" in summ.columns:\n",
    "                    expected_mean = float(summ.iloc[0][\"mean_T_LOO\"])\n",
    "                    if abs(expected_mean - meanT) > TOL_MEAN:\n",
    "                        errors.append(f\"LOO mean mismatch summary vs recompute: {expected_mean} vs {meanT:.6f}\")\n",
    "            # t-test (recompute)\n",
    "            tstat, pvalue = stats.ttest_1samp(loo[\"T_log\"].dropna(), 0.0, alternative='two-sided')\n",
    "            print(f\"Recomputed t-test: t={tstat:.4f}, p={pvalue:.6e}\")\n",
    "\n",
    "# Sanitized files check for NaN/Inf\n",
    "for p in [sanitized_summary, sanitized_loo]:\n",
    "    if os.path.exists(p):\n",
    "        df = pd.read_csv(p)\n",
    "        numcols = df.select_dtypes(include=[np.number]).columns\n",
    "        if df[numcols].isna().sum().sum() > 0:\n",
    "            errors.append(f\"NaN found in numeric columns after sanitization in {p}\")\n",
    "        if np.isinf(df[numcols].to_numpy()).sum() > 0:\n",
    "            errors.append(f\"Inf found in numeric columns after sanitization in {p}\")\n",
    "\n",
    "# Basic sweep check\n",
    "if os.path.exists(sweep_summary):\n",
    "    s = pd.read_csv(sweep_summary)\n",
    "    if not {\"fraction\",\"match_frac\",\"unstable_frac\"}.issubset(s.columns):\n",
    "        errors.append(\"Sweep summary missing expected columns\")\n",
    "\n",
    "# Temporal index check (flag_for_review)\n",
    "if os.path.exists(temporal_index):\n",
    "    t = pd.read_csv(temporal_index)\n",
    "    if \"flag_for_review\" in t.columns:\n",
    "        flagged = t[t[\"flag_for_review\"]==True]\n",
    "        print(f\"Temporal CV: {len(flagged)} windows flagged for review\")\n",
    "    else:\n",
    "        print(\"Temporal index present but no flag_for_review column\")\n",
    "\n",
    "# Final report\n",
    "if errors:\n",
    "    print(\"\\nTESTS FAIL - issues list:\")\n",
    "    for e in errors:\n",
    "        print(\" -\", e)\n",
    "    raise AssertionError(\"One or more checks failed (see list above).\")\n",
    "else:\n",
    "    print(\"\\nAll checks passed (minimal pipeline A smoke tests).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c8d18",
   "metadata": {
    "id": "_89b_KiNsBAL"
   },
   "source": [
    "Interprétation courte des résultats actuels\n",
    "\n",
    "LOO mean T_log = -0.353046 avec std = 0.086006 indique un effet stable mais la relative std 24.36% montre sensibilité locale importante.\n",
    "\n",
    "Le t-test rejette H0 (p ≈ 1.5e-13) — l’effet T_log est statistiquement significatif.\n",
    "\n",
    "19 fenêtres temporelles sont marquées pour review ; plusieurs fenêtres montrent une ville avec max_city_outlier_frac ≈ 0.48–0.54.\n",
    "\n",
    "D’après diagnostics globaux, les features les plus suspectes sont precipitation_mm et urban_heat_island_intensity ; les grandes villes (ex. New York, Los Angeles, Chicago, Houston, Phoenix, Philadelphia) figurent dans les séries sauvegardées et méritent une inspection prioritaire.\n",
    "\n",
    "Liste prioritaire détaillée d’investigation (ordre d’exécution)\n",
    "Identifier pour chaque fenêtre la ville ayant la plus grande max_city_outlier_frac (single top offender).\n",
    "\n",
    "Pour ces villes (top offender par fenêtre), examiner les features responsables en regardant la proportion d’outliers par feature et les top‑3 indices d’outliers.\n",
    "\n",
    "Vérifier si precipitation_mm et urban_heat_island_intensity concentrent les outliers ; si oui, prioriser : a) winsorisation, b) log1p sur precipitation_mm, c) vérifier erreur d’enregistrement / unité.\n",
    "\n",
    "Effectuer influence test LOO‑city : recalculer T_log en excluant la ville top‑offender et mesurer delta T_log. Prioriser villes avec |delta T_log| élevé.\n",
    "\n",
    "Pour chaque ville priorisée, produire plots : timeseries, box+points, et scatter (feature vs MD) pour détecter mécanismes (sauts, erreurs de capteur, vraie variabilité).\n",
    "\n",
    "Après corrections (winsor / transform / exclusion conditionnelle), recomputer les métriques clefs : prop_obs_outlier, max_city_outlier_frac, LOO mean T_log, rel_std_pct, p‑value. Chercher prop_obs_outlier < 5% et max_city_outlier_frac < 25% comme objectif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f1a80",
   "metadata": {
    "id": "gy1KxQ0EsH4S"
   },
   "source": [
    "Cellule Python — extraction prioritaire villes/diagnostics + tests applicables (winsor/log1p/exclude-city LOO)\n",
    "Collez et exécutez dans le notebook. La cellule :\n",
    "\n",
    "lit l’index enrichi et les CSV by_city/raw listés ;\n",
    "\n",
    "calcule, par fenêtre, la ville top‑offender (max fraction d’outliers) et la fraction d’outliers par feature pour cette ville ;\n",
    "\n",
    "exécute trois tests rapides sur la fenêtre ciblée (winsor 1–99% sur precipitation_mm, log1p(precipitation_mm), exclusion de la ville top‑offender) et recalcule T_log approximé (utilise la même logique d_estimate moyenne d_participation/PCA90 et T_log = (d-4)*ln(n_eff)) ;\n",
    "\n",
    "sauvegarde un CSV résumé tests : results/temporal_cv_atypical_windows/diagnostics/tests_priority_summary.csv et crée plots pour la fenêtre testée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "215ccbf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22622,
     "status": "ok",
     "timestamp": 1761434777459,
     "user": {
      "displayName": "GlobalZivotPrint",
      "userId": "12055292741917834281"
     },
     "user_tz": 240
    },
    "id": "LOgrSDZosNRE",
    "outputId": "be9bd5ac-992e-4894-d35d-b9e6b979f807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priority tests summary written to: results/temporal_cv_atypical_windows/diagnostics/tests_priority_summary.csv\n",
      "Per-window plots saved under: results/temporal_cv_atypical_windows/diagnostics/priority_tests\n"
     ]
    }
   ],
   "source": [
    "# Priority extraction + quick sensitivity tests (winsor / log1p / exclude-city LOO)\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IDX = 'results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_windows_index_enriched.csv'\n",
    "OUT_SUM = 'results/temporal_cv_atypical_windows/diagnostics/tests_priority_summary.csv'\n",
    "OUT_DIR = 'results/temporal_cv_atypical_windows/diagnostics/priority_tests'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def safe_tag(s): return re.sub(r'[^0-9A-Za-z_.-]', '_', str(s))\n",
    "\n",
    "def compute_d_estimate_from_X(X):\n",
    "    # X: cities x features numeric (no NaN)\n",
    "    if X.shape[0] < 2 or X.shape[1] < 1:\n",
    "        return np.nan, np.nan\n",
    "    cov = np.cov(X, rowvar=False)\n",
    "    eigvals = np.linalg.eigvalsh(cov)\n",
    "    eigvals = np.maximum(eigvals, 0.0)\n",
    "    sum_eig = np.sum(eigvals)\n",
    "    d_part = 0.0 if sum_eig <= 0 else (sum_eig**2) / np.sum(eigvals**2)\n",
    "    pca = PCA(n_components=min(X.shape[0], X.shape[1])).fit(X)\n",
    "    cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d_pca90 = int(np.searchsorted(cumvar, 0.90) + 1) if cumvar[-1] >= 0.90 else pca.n_components_\n",
    "    d_est = float((d_part + d_pca90)/2.0)\n",
    "    return d_part, d_pca90, d_est\n",
    "\n",
    "def compute_T_log(d_est, n_eff):\n",
    "    n_eff = max(2, int(n_eff))\n",
    "    return (d_est - 4.0) * np.log(n_eff)\n",
    "\n",
    "if not os.path.exists(IDX):\n",
    "    raise FileNotFoundError(IDX)\n",
    "\n",
    "idx = pd.read_csv(IDX)\n",
    "summary_rows = []\n",
    "\n",
    "# Prefer features list discovered in diagnostics/features files or use default list\n",
    "DEFAULT_FEATURES = ['temperature_celsius','humidity_percent','precipitation_mm','wind_speed_ms','urban_heat_island_intensity']\n",
    "\n",
    "for _, r in idx.iterrows():\n",
    "    raw = r['raw_csv']\n",
    "    by_city = r.get('city_summary_csv', None)\n",
    "    tag = safe_tag(f\"{r['window_type']}_{r['window_center']}_{r['pipeline']}\")\n",
    "    row_out = {'tag': tag, 'window_type': r['window_type'], 'window_center': r['window_center'],\n",
    "               'pipeline': r['pipeline'], 'n_rows': int(r.get('n_rows', 0)),\n",
    "               'prop_obs_outlier': r.get('prop_obs_outlier'), 'median_md': r.get('median_md'),\n",
    "               'prop_cities_with_gt10pct_outliers': r.get('prop_cities_with_gt10pct_outliers'),\n",
    "               'max_city_outlier_frac': r.get('max_city_outlier_frac'), 'flag_for_review': r.get('flag_for_review')}\n",
    "    if not by_city or not os.path.exists(by_city):\n",
    "        # try to find by_city in diagnostics folder\n",
    "        candidate = glob.glob(os.path.join('results','temporal_cv_atypical_windows','diagnostics', tag, f\"diagnostics_by_city_{tag}.csv\"))\n",
    "        by_city = candidate[0] if candidate else None\n",
    "    if not raw or not os.path.exists(raw):\n",
    "        summary_rows.append(row_out)\n",
    "        continue\n",
    "    df_raw = pd.read_csv(raw)\n",
    "    # Ensure city_key\n",
    "    if 'city_key' not in df_raw.columns:\n",
    "        agg_cols = [c for c in ['city','country','latitude','longitude'] if c in df_raw.columns]\n",
    "        df_raw['city_key'] = df_raw[agg_cols].astype(str).agg('_'.join, axis=1) if agg_cols else 'unknown'\n",
    "    # detect numeric feature columns\n",
    "    num_cols = [c for c in df_raw.select_dtypes(include=[np.number]).columns.tolist() if c not in ['year','month','n_rows']]\n",
    "    features = [c for c in DEFAULT_FEATURES if c in num_cols] or (num_cols[:5] if num_cols else [])\n",
    "    row_out['features_used'] = ';'.join(features)\n",
    "    # if by_city exists, read per-city summary to identify top offender\n",
    "    top_city = None\n",
    "    top_frac = np.nan\n",
    "    per_city_df = None\n",
    "    if by_city and os.path.exists(by_city):\n",
    "        per_city_df = pd.read_csv(by_city)\n",
    "        # detect possible outlier fraction cols\n",
    "        frac_cols = [c for c in per_city_df.columns if 'outlier' in c.lower() or 'frac' in c.lower()]\n",
    "        if frac_cols:\n",
    "            # take first frac-like column\n",
    "            fcol = frac_cols[0]\n",
    "            per_city_df = per_city_df.sort_values(fcol, ascending=False)\n",
    "            top_city = per_city_df.iloc[0]['city_key']\n",
    "            top_frac = float(per_city_df.iloc[0].get(fcol, np.nan))\n",
    "        else:\n",
    "            # fallback: use n_obs to pick representative city\n",
    "            per_city_df = per_city_df.sort_values('n_obs', ascending=False)\n",
    "            top_city = per_city_df.iloc[0]['city_key']\n",
    "            top_frac = np.nan\n",
    "    else:\n",
    "        # compute naive per-city outlier fraction using Mahalanobis MD if present\n",
    "        if 'mahalanobis_md' in df_raw.columns:\n",
    "            g = df_raw.groupby('city_key')\n",
    "            city_fracs = {}\n",
    "            md = df_raw['mahalanobis_md'].values\n",
    "            thresh = np.nanpercentile(md, 97.5)\n",
    "            is_out = md >= thresh\n",
    "            for city, grp in g:\n",
    "                inds = grp.index.to_numpy()\n",
    "                city_fracs[city] = np.nansum(is_out[inds]) / max(1, inds.size)\n",
    "            if city_fracs:\n",
    "                top_city = max(city_fracs, key=city_fracs.get)\n",
    "                top_frac = city_fracs[top_city]\n",
    "            per_city_df = pd.DataFrame([{'city_key':k,'outlier_frac':v} for k,v in city_fracs.items()]).sort_values('outlier_frac', ascending=False)\n",
    "    row_out['top_city'] = top_city\n",
    "    row_out['top_city_frac'] = top_frac\n",
    "\n",
    "    # If top_city available, compute per-feature fraction of extreme rows in that city\n",
    "    feat_out_fracs = {}\n",
    "    if top_city is not None:\n",
    "        city_rows = df_raw[df_raw['city_key']==top_city]\n",
    "        for feat in features:\n",
    "            if feat in city_rows.columns:\n",
    "                col = city_rows[feat].dropna().astype(float)\n",
    "                if col.empty:\n",
    "                    feat_out_fracs[feat] = np.nan\n",
    "                else:\n",
    "                    # extreme using empirical 97.5% across entire raw feature distribution\n",
    "                    global_thresh_hi = np.nanpercentile(df_raw[feat].dropna(), 97.5)\n",
    "                    global_thresh_lo = np.nanpercentile(df_raw[feat].dropna(), 2.5)\n",
    "                    n_ext = ((col >= global_thresh_hi) | (col <= global_thresh_lo)).sum()\n",
    "                    feat_out_fracs[feat] = float(n_ext) / max(1, col.shape[0])\n",
    "        row_out['top_city_feat_outlier_fracs'] = ';'.join([f\"{k}:{v:.3f}\" for k,v in feat_out_fracs.items()])\n",
    "    else:\n",
    "        row_out['top_city_feat_outlier_fracs'] = ''\n",
    "\n",
    "    # Quick sensitivity tests: construct per-city aggregate X (mean per city), standardize, compute d_est and T_log baseline\n",
    "    city_df = df_raw.groupby('city_key')[features].mean().reset_index()\n",
    "    X = city_df[features].dropna().astype(float).values\n",
    "    if X.size == 0 or X.shape[0] < 2:\n",
    "        row_out.update({'d_part':np.nan,'d_pca90':np.nan,'d_est':np.nan,'T_log':np.nan})\n",
    "        summary_rows.append(row_out); continue\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "    d_part, d_pca90, d_est = compute_d_estimate_from_X(Xs)\n",
    "    T_log_base = compute_T_log(d_est, Xs.shape[0])\n",
    "    row_out.update({'d_part':d_part,'d_pca90':d_pca90,'d_est':d_est,'T_log':T_log_base})\n",
    "\n",
    "    # Test 1: winsorize precipitation_mm at 1-99% (if present)\n",
    "    test_results = {}\n",
    "    if 'precipitation_mm' in features:\n",
    "        df_w = df_raw.copy()\n",
    "        lo, hi = np.nanpercentile(df_w['precipitation_mm'], [1,99])\n",
    "        df_w['precipitation_mm'] = df_w['precipitation_mm'].clip(lo, hi)\n",
    "        city_df_w = df_w.groupby('city_key')[features].mean().reset_index()\n",
    "        Xw = city_df_w[features].dropna().astype(float).values\n",
    "        if Xw.shape[0] >= 2:\n",
    "            Xs_w = scaler.fit_transform(Xw)\n",
    "            _,_, d_est_w = compute_d_estimate_from_X(Xs_w)\n",
    "            T_w = compute_T_log(d_est_w, Xs_w.shape[0])\n",
    "            test_results['winsor_precip_T_log'] = T_w\n",
    "        else:\n",
    "            test_results['winsor_precip_T_log'] = np.nan\n",
    "    else:\n",
    "        test_results['winsor_precip_T_log'] = np.nan\n",
    "\n",
    "    # Test 2: log1p transform precipitation_mm\n",
    "    if 'precipitation_mm' in features:\n",
    "        df_l = df_raw.copy()\n",
    "        df_l['precipitation_mm'] = np.log1p(df_l['precipitation_mm'].clip(lower=0.0))\n",
    "        city_df_l = df_l.groupby('city_key')[features].mean().reset_index()\n",
    "        Xl = city_df_l[features].dropna().astype(float).values\n",
    "        if Xl.shape[0] >= 2:\n",
    "            Xs_l = scaler.fit_transform(Xl)\n",
    "            _,_, d_est_l = compute_d_estimate_from_X(Xs_l)\n",
    "            T_l = compute_T_log(d_est_l, Xs_l.shape[0])\n",
    "            test_results['log1p_precip_T_log'] = T_l\n",
    "        else:\n",
    "            test_results['log1p_precip_T_log'] = np.nan\n",
    "    else:\n",
    "        test_results['log1p_precip_T_log'] = np.nan\n",
    "\n",
    "    # Test 3: exclude top_city and recompute (city influence)\n",
    "    if top_city is not None:\n",
    "        city_df_ex = city_df[city_df['city_key'] != top_city]\n",
    "        Xex = city_df_ex[features].dropna().astype(float).values\n",
    "        if Xex.shape[0] >= 2:\n",
    "            Xs_ex = scaler.fit_transform(Xex)\n",
    "            _,_, d_est_ex = compute_d_estimate_from_X(Xs_ex)\n",
    "            T_ex = compute_T_log(d_est_ex, Xs_ex.shape[0])\n",
    "            test_results['exclude_topcity_T_log'] = T_ex\n",
    "            test_results['delta_T_log_exclude_topcity'] = T_ex - T_log_base\n",
    "        else:\n",
    "            test_results['exclude_topcity_T_log'] = np.nan\n",
    "            test_results['delta_T_log_exclude_topcity'] = np.nan\n",
    "    else:\n",
    "        test_results['exclude_topcity_T_log'] = np.nan\n",
    "        test_results['delta_T_log_exclude_topcity'] = np.nan\n",
    "\n",
    "    # attach tests to row\n",
    "    for k,v in test_results.items():\n",
    "        row_out[k] = float(v) if (v is not None and not pd.isna(v)) else np.nan\n",
    "\n",
    "    # Save quick plots for this window (top city timeseries + box for precipitation)\n",
    "    try:\n",
    "        fig_dir = os.path.join(OUT_DIR, tag)\n",
    "        os.makedirs(fig_dir, exist_ok=True)\n",
    "        if top_city is not None:\n",
    "            df_city = df_raw[df_raw['city_key']==top_city]\n",
    "            if 'precipitation_mm' in df_city.columns:\n",
    "                plt.figure(figsize=(8,3))\n",
    "                plt.plot(df_city['precipitation_mm'].values, marker='o', linestyle='-', markersize=3)\n",
    "                plt.title(f'{tag} - precipitation_mm timeseries - top city {top_city}')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(fig_dir, f\"{tag}_topcity_precip_timeseries.png\"), dpi=150)\n",
    "                plt.close()\n",
    "            # boxplot of features for top city vs global\n",
    "            for feat in features:\n",
    "                plt.figure(figsize=(6,3))\n",
    "                data = [df_raw[feat].dropna().values, df_city[feat].dropna().values]\n",
    "                plt.boxplot(data, labels=['global','top_city'])\n",
    "                plt.title(f'{tag} - box {feat} global vs {top_city}')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(fig_dir, f\"{tag}_box_{feat}.png\"), dpi=150)\n",
    "                plt.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    summary_rows.append(row_out)\n",
    "\n",
    "# write summary CSV\n",
    "pd.DataFrame(summary_rows).to_csv(OUT_SUM, index=False)\n",
    "print(\"Priority tests summary written to:\", OUT_SUM)\n",
    "print(\"Per-window plots saved under:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMj8BTKhAxEVfHfc0L9NwkV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
