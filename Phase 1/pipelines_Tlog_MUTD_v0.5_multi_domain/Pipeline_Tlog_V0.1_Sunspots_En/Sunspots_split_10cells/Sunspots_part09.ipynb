{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d6b1b4",
   "metadata": {},
   "source": [
    "Cell Python — Recompute d_s robust (Theil‑Sen) for every bootstrap b, pair with Levina, run paired tests and save figures/CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9706468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b=1: levina=7.857, eigvals=400, lam_unique=400\n",
      "b=2: levina=7.934, eigvals=400, lam_unique=400\n",
      "b=3: levina=7.910, eigvals=400, lam_unique=400\n",
      "b=4: levina=7.854, eigvals=400, lam_unique=400\n",
      "b=5: levina=7.886, eigvals=400, lam_unique=400\n",
      "b=6: levina=7.898, eigvals=400, lam_unique=400\n",
      "b=7: levina=7.937, eigvals=400, lam_unique=400\n",
      "b=8: levina=7.912, eigvals=400, lam_unique=400\n",
      "b=9: levina=8.002, eigvals=400, lam_unique=400\n",
      "b=10: levina=7.906, eigvals=400, lam_unique=400\n",
      "b=11: levina=7.906, eigvals=400, lam_unique=400\n",
      "b=12: levina=7.877, eigvals=400, lam_unique=400\n",
      "b=13: levina=7.958, eigvals=400, lam_unique=400\n",
      "b=14: levina=7.941, eigvals=400, lam_unique=400\n",
      "b=15: levina=7.957, eigvals=400, lam_unique=400\n",
      "b=16: levina=7.980, eigvals=400, lam_unique=400\n",
      "b=17: levina=7.986, eigvals=400, lam_unique=400\n",
      "b=18: levina=7.995, eigvals=400, lam_unique=400\n",
      "b=19: levina=7.923, eigvals=400, lam_unique=400\n",
      "b=20: levina=7.956, eigvals=400, lam_unique=400\n",
      "b=21: levina=7.930, eigvals=400, lam_unique=400\n",
      "b=22: levina=7.955, eigvals=400, lam_unique=400\n",
      "b=23: levina=7.870, eigvals=400, lam_unique=400\n",
      "b=24: levina=7.977, eigvals=400, lam_unique=400\n",
      "b=25: levina=8.013, eigvals=400, lam_unique=400\n",
      "b=26: levina=8.008, eigvals=400, lam_unique=400\n",
      "b=27: levina=7.912, eigvals=400, lam_unique=400\n",
      "b=28: levina=7.978, eigvals=400, lam_unique=400\n",
      "b=29: levina=7.862, eigvals=400, lam_unique=400\n",
      "b=30: levina=8.064, eigvals=400, lam_unique=400\n",
      "b=31: levina=7.871, eigvals=400, lam_unique=400\n",
      "b=32: levina=7.827, eigvals=400, lam_unique=400\n",
      "b=33: levina=7.928, eigvals=400, lam_unique=400\n",
      "b=34: levina=7.902, eigvals=400, lam_unique=400\n",
      "b=35: levina=7.862, eigvals=400, lam_unique=400\n",
      "b=36: levina=7.956, eigvals=400, lam_unique=400\n",
      "b=37: levina=7.953, eigvals=400, lam_unique=400\n",
      "b=38: levina=7.977, eigvals=400, lam_unique=400\n",
      "b=39: levina=7.968, eigvals=400, lam_unique=400\n",
      "b=40: levina=7.874, eigvals=400, lam_unique=400\n",
      "b=41: levina=7.988, eigvals=400, lam_unique=400\n",
      "b=42: levina=7.938, eigvals=400, lam_unique=400\n",
      "b=43: levina=7.993, eigvals=400, lam_unique=400\n",
      "b=44: levina=7.880, eigvals=400, lam_unique=400\n",
      "b=45: levina=7.957, eigvals=400, lam_unique=400\n",
      "b=46: levina=7.921, eigvals=400, lam_unique=400\n",
      "b=47: levina=7.939, eigvals=400, lam_unique=400\n",
      "b=48: levina=7.954, eigvals=400, lam_unique=400\n",
      "b=49: levina=7.998, eigvals=400, lam_unique=400\n",
      "b=50: levina=7.918, eigvals=400, lam_unique=400\n",
      "b=51: levina=7.878, eigvals=400, lam_unique=400\n",
      "b=52: levina=7.891, eigvals=400, lam_unique=400\n",
      "b=53: levina=7.949, eigvals=400, lam_unique=400\n",
      "b=54: levina=7.961, eigvals=400, lam_unique=400\n",
      "b=55: levina=7.955, eigvals=400, lam_unique=400\n",
      "b=56: levina=7.923, eigvals=400, lam_unique=400\n",
      "b=57: levina=7.936, eigvals=400, lam_unique=400\n",
      "b=58: levina=7.842, eigvals=400, lam_unique=400\n",
      "b=59: levina=7.935, eigvals=400, lam_unique=400\n",
      "b=60: levina=7.948, eigvals=400, lam_unique=400\n",
      "b=61: levina=7.939, eigvals=400, lam_unique=400\n",
      "b=62: levina=7.789, eigvals=400, lam_unique=400\n",
      "b=63: levina=8.022, eigvals=400, lam_unique=400\n",
      "b=64: levina=8.039, eigvals=400, lam_unique=400\n",
      "b=65: levina=7.940, eigvals=400, lam_unique=400\n",
      "b=66: levina=7.876, eigvals=400, lam_unique=400\n",
      "b=67: levina=7.915, eigvals=400, lam_unique=400\n",
      "b=68: levina=7.981, eigvals=400, lam_unique=400\n",
      "b=69: levina=7.900, eigvals=400, lam_unique=400\n",
      "b=70: levina=7.855, eigvals=400, lam_unique=400\n",
      "b=71: levina=8.025, eigvals=400, lam_unique=400\n",
      "b=72: levina=7.987, eigvals=400, lam_unique=400\n",
      "b=73: levina=7.908, eigvals=400, lam_unique=400\n",
      "b=74: levina=7.887, eigvals=400, lam_unique=400\n",
      "b=75: levina=7.961, eigvals=400, lam_unique=400\n",
      "b=76: levina=7.996, eigvals=400, lam_unique=400\n",
      "b=77: levina=7.923, eigvals=400, lam_unique=400\n",
      "b=78: levina=7.888, eigvals=400, lam_unique=400\n",
      "b=79: levina=7.870, eigvals=400, lam_unique=400\n",
      "b=80: levina=8.010, eigvals=400, lam_unique=400\n",
      "b=81: levina=7.958, eigvals=400, lam_unique=400\n",
      "b=82: levina=7.966, eigvals=400, lam_unique=400\n",
      "b=83: levina=7.936, eigvals=400, lam_unique=400\n",
      "b=84: levina=7.875, eigvals=400, lam_unique=400\n",
      "b=85: levina=7.921, eigvals=400, lam_unique=400\n",
      "b=86: levina=7.988, eigvals=400, lam_unique=400\n",
      "b=87: levina=7.936, eigvals=400, lam_unique=400\n",
      "b=88: levina=7.875, eigvals=400, lam_unique=400\n",
      "b=89: levina=7.941, eigvals=400, lam_unique=400\n",
      "b=90: levina=7.893, eigvals=400, lam_unique=400\n",
      "b=91: levina=7.807, eigvals=400, lam_unique=400\n",
      "b=92: levina=8.015, eigvals=400, lam_unique=400\n",
      "b=93: levina=7.951, eigvals=400, lam_unique=400\n",
      "b=94: levina=7.922, eigvals=400, lam_unique=400\n",
      "b=95: levina=7.944, eigvals=400, lam_unique=400\n",
      "b=96: levina=7.988, eigvals=400, lam_unique=400\n",
      "b=97: levina=7.939, eigvals=400, lam_unique=400\n",
      "b=98: levina=7.946, eigvals=400, lam_unique=400\n",
      "b=99: levina=7.907, eigvals=400, lam_unique=400\n",
      "b=100: levina=7.982, eigvals=400, lam_unique=400\n",
      "b=101: levina=7.898, eigvals=400, lam_unique=400\n",
      "b=102: levina=7.924, eigvals=400, lam_unique=400\n",
      "b=103: levina=7.952, eigvals=400, lam_unique=400\n",
      "b=104: levina=7.985, eigvals=400, lam_unique=400\n",
      "b=105: levina=7.931, eigvals=400, lam_unique=400\n",
      "b=106: levina=7.968, eigvals=400, lam_unique=400\n",
      "b=107: levina=7.906, eigvals=400, lam_unique=400\n",
      "b=108: levina=7.943, eigvals=400, lam_unique=400\n",
      "b=109: levina=8.004, eigvals=400, lam_unique=400\n",
      "b=110: levina=7.981, eigvals=400, lam_unique=400\n",
      "b=111: levina=7.995, eigvals=400, lam_unique=400\n",
      "b=112: levina=7.899, eigvals=400, lam_unique=400\n",
      "b=113: levina=7.956, eigvals=400, lam_unique=400\n",
      "b=114: levina=7.940, eigvals=400, lam_unique=400\n",
      "b=115: levina=8.016, eigvals=400, lam_unique=400\n",
      "b=116: levina=7.972, eigvals=400, lam_unique=400\n",
      "b=117: levina=7.884, eigvals=400, lam_unique=400\n",
      "b=118: levina=8.025, eigvals=400, lam_unique=400\n",
      "b=119: levina=7.909, eigvals=400, lam_unique=400\n",
      "b=120: levina=7.897, eigvals=400, lam_unique=400\n",
      "b=121: levina=7.900, eigvals=400, lam_unique=400\n",
      "b=122: levina=7.969, eigvals=400, lam_unique=400\n",
      "b=123: levina=7.981, eigvals=400, lam_unique=400\n",
      "b=124: levina=7.992, eigvals=400, lam_unique=400\n",
      "b=125: levina=7.997, eigvals=400, lam_unique=400\n",
      "b=126: levina=7.929, eigvals=400, lam_unique=400\n",
      "b=127: levina=7.909, eigvals=400, lam_unique=400\n",
      "b=128: levina=7.951, eigvals=400, lam_unique=400\n",
      "b=129: levina=8.006, eigvals=400, lam_unique=400\n",
      "b=130: levina=7.902, eigvals=400, lam_unique=400\n",
      "b=131: levina=7.821, eigvals=400, lam_unique=400\n",
      "b=132: levina=7.940, eigvals=400, lam_unique=400\n",
      "b=133: levina=7.969, eigvals=400, lam_unique=400\n",
      "b=134: levina=7.935, eigvals=400, lam_unique=400\n",
      "b=135: levina=7.880, eigvals=400, lam_unique=400\n",
      "b=136: levina=7.899, eigvals=400, lam_unique=400\n",
      "b=137: levina=7.982, eigvals=400, lam_unique=400\n",
      "b=138: levina=8.017, eigvals=400, lam_unique=400\n",
      "b=139: levina=7.991, eigvals=400, lam_unique=400\n",
      "b=140: levina=8.033, eigvals=400, lam_unique=400\n",
      "b=141: levina=7.959, eigvals=400, lam_unique=400\n",
      "b=142: levina=8.085, eigvals=400, lam_unique=400\n",
      "b=143: levina=7.933, eigvals=400, lam_unique=400\n",
      "b=144: levina=7.926, eigvals=400, lam_unique=400\n",
      "b=145: levina=7.894, eigvals=400, lam_unique=400\n",
      "b=146: levina=7.991, eigvals=400, lam_unique=400\n",
      "b=147: levina=8.050, eigvals=400, lam_unique=400\n",
      "b=148: levina=8.018, eigvals=400, lam_unique=400\n",
      "b=149: levina=7.931, eigvals=400, lam_unique=400\n",
      "b=150: levina=8.020, eigvals=400, lam_unique=400\n",
      "Saved Theil-Sen raw: results/paired_levina_spectral_theilsen\\paired_levina_spectral_theilsen_raw.csv\n",
      "Saved tests summary: results/paired_levina_spectral_theilsen\\paired_levina_spectral_theilsen_tests_summary.csv\n",
      "Saved plots and CSVs to results/paired_levina_spectral_theilsen\n"
     ]
    }
   ],
   "source": [
    "# Cell corrigée : compute Theil-Sen d_s per bootstrap b (for chosen lambda_max list),\n",
    "# pair with Levina (from results/levina_bickel_boot_samples.csv), run paired tests and save figures/CSVs\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "\n",
    "# --- Parameters (edit if needed) ---\n",
    "csv_path = 'data/sunspots_raw/Sunspots.csv'\n",
    "levina_samples_path = 'results/levina_bickel_boot_samples.csv'   # required\n",
    "out_dir = 'results/paired_levina_spectral_theilsen'\n",
    "embedding_dim = 10\n",
    "tau = 1\n",
    "k_neighbors = 10\n",
    "n_eig = 400\n",
    "subsample_frac = 0.6\n",
    "rng_seed = 42\n",
    "lambda_max_list = [0.1, 0.2, 0.4]\n",
    "min_points_for_fit = 4\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# --- Utilities ---\n",
    "def takens_embed(x, dim, tau):\n",
    "    m = len(x) - (dim - 1) * tau\n",
    "    if m <= 0:\n",
    "        return None\n",
    "    embed = np.empty((m, dim))\n",
    "    for i in range(dim):\n",
    "        embed[:, i] = x[i * tau : i * tau + m]\n",
    "    return embed\n",
    "\n",
    "def build_laplacian_eigs(X_points, k_neighbors, n_eig):\n",
    "    n_nodes_local = X_points.shape[0]\n",
    "    nbrs = NearestNeighbors(n_neighbors=min(k_neighbors + 1, n_nodes_local), algorithm='auto').fit(X_points)\n",
    "    distances, indices = nbrs.kneighbors(X_points)\n",
    "    adj = sparse.lil_matrix((n_nodes_local, n_nodes_local), dtype=np.float32)\n",
    "    for i in range(n_nodes_local):\n",
    "        for j in indices[i, 1:]:\n",
    "            adj[i, j] = 1.0\n",
    "            adj[j, i] = 1.0\n",
    "    adj = adj.tocsr()\n",
    "    deg = np.array(adj.sum(axis=1)).flatten()\n",
    "    deg[deg == 0] = 1.0\n",
    "    D_inv_sqrt = sparse.diags(1.0 / np.sqrt(deg))\n",
    "    I = sparse.identity(n_nodes_local, format='csr')\n",
    "    L_norm = I - D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "    n_eig_local = min(n_eig, n_nodes_local - 1)\n",
    "    try:\n",
    "        eigvals, _ = eigsh(L_norm, k=n_eig_local, which='SM', tol=1e-6, maxiter=5000)\n",
    "    except Exception:\n",
    "        try:\n",
    "            from scipy.linalg import eigh\n",
    "            Ld = L_norm.toarray()\n",
    "            eigvals_all = eigh(Ld, eigvals_only=True)\n",
    "            eigvals = np.sort(eigvals_all)[:n_eig_local]\n",
    "        except Exception as e:\n",
    "            print(\"Eigen decomposition failed:\", e)\n",
    "            return None\n",
    "    return np.sort(eigvals)\n",
    "\n",
    "def spectral_counting(eigvals):\n",
    "    eps = 1e-12\n",
    "    lams = eigvals[eigvals > eps]\n",
    "    lam_vals = np.unique(lams)\n",
    "    N_vals = np.array([np.searchsorted(lams, lam, side='right') for lam in lam_vals])\n",
    "    return lam_vals, N_vals\n",
    "\n",
    "def fit_theilsen_loglog(lam_fit, N_fit):\n",
    "    if len(lam_fit) < 2:\n",
    "        return None\n",
    "    x = np.log(lam_fit).reshape(-1, 1)\n",
    "    y = np.log(N_fit)\n",
    "    if len(x) < 3:\n",
    "        slope, intercept, r_value, p_value, stderr = stats.linregress(x.flatten(), y)\n",
    "        return {'slope': float(slope), 'intercept': float(intercept), 'n': len(x)}\n",
    "    ts = TheilSenRegressor(random_state=0)\n",
    "    ts.fit(x, y)\n",
    "    return {'slope': float(ts.coef_[0]), 'intercept': float(ts.intercept_), 'n': len(x)}\n",
    "\n",
    "# --- Load Levina samples ---\n",
    "if not os.path.exists(levina_samples_path):\n",
    "    raise RuntimeError(f\"Levina samples not found: {levina_samples_path}\")\n",
    "lev_df = pd.read_csv(levina_samples_path)\n",
    "if 'b' not in lev_df.columns:\n",
    "    raise RuntimeError(\"levina_bickel_boot_samples.csv must contain column 'b'\")\n",
    "if 'levina_mle' not in lev_df.columns:\n",
    "    # if levina_mle column absent, try column name 'm_hat' or abort\n",
    "    alt = next((c for c in lev_df.columns if 'levina' in c or 'm_hat' in c), None)\n",
    "    if alt is None:\n",
    "        raise RuntimeError(\"levina_bickel_boot_samples.csv missing 'levina_mle' column\")\n",
    "    lev_df = lev_df.rename(columns={alt: 'levina_mle'})\n",
    "\n",
    "# --- Build embedding once ---\n",
    "df0 = pd.read_csv(csv_path)\n",
    "value_col_candidates = ['Number', 'Total Sunspot', 'Total Sunspot Number', 'Monthly Mean']\n",
    "col = next((c for c in value_col_candidates if c in df0.columns), None)\n",
    "if col is None:\n",
    "    numeric_cols = df0.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not numeric_cols:\n",
    "        raise RuntimeError(\"No numeric column found in CSV.\")\n",
    "    col = numeric_cols[-1]\n",
    "series = pd.to_numeric(df0[col], errors='coerce').dropna().values\n",
    "X_full = takens_embed(series, embedding_dim, tau)\n",
    "if X_full is None:\n",
    "    raise RuntimeError(\"Embedding too short for given embedding_dim/tau.\")\n",
    "n_nodes = X_full.shape[0]\n",
    "\n",
    "# Recreate deterministic bootstrap indices (must match Levina run)\n",
    "n_boot = int(lev_df['b'].max())\n",
    "rng = default_rng(rng_seed)\n",
    "indices_list = [rng.choice(np.arange(n_nodes), size=max(120, int(np.floor(subsample_frac * n_nodes))), replace=False)\n",
    "                for _ in range(n_boot)]\n",
    "\n",
    "# --- For each bootstrap b and each lambda_max, recompute Theil-Sen slope and d_s = 2*slope ---\n",
    "rows = []\n",
    "for b_val in sorted(lev_df['b'].unique()):\n",
    "    b_idx = int(b_val)\n",
    "    levina_row = lev_df[lev_df['b'] == b_idx].iloc[0]\n",
    "    levina_val = float(levina_row['levina_mle'])\n",
    "    if b_idx < 1 or b_idx > len(indices_list):\n",
    "        print(f\"Skipping b={b_idx} (index out of range)\")\n",
    "        continue\n",
    "    idx = indices_list[b_idx - 1]\n",
    "    X_sub = X_full[idx, :]\n",
    "    eigvals = build_laplacian_eigs(X_sub, k_neighbors, n_eig)\n",
    "    if eigvals is None:\n",
    "        for lm in lambda_max_list:\n",
    "            rows.append({'b': b_idx, 'lambda_max': lm, 'levina_mle': levina_val,\n",
    "                         'theilsen_slope': np.nan, 'theilsen_d_s': np.nan, 'n_points_fit': 0, 'fit_ok': False})\n",
    "        continue\n",
    "    lam_vals, N_vals = spectral_counting(eigvals)\n",
    "    for lm in lambda_max_list:\n",
    "        mask = lam_vals <= lm\n",
    "        lam_fit = lam_vals[mask]\n",
    "        N_fit = N_vals[mask]\n",
    "        n_points = int(len(lam_fit))\n",
    "        fit_ok = n_points >= min_points_for_fit\n",
    "        if fit_ok:\n",
    "            ts_res = fit_theilsen_loglog(lam_fit, N_fit)\n",
    "            slope_ts = ts_res['slope'] if ts_res is not None else np.nan\n",
    "            d_s_ts = 2.0 * slope_ts if np.isfinite(slope_ts) else np.nan\n",
    "        else:\n",
    "            slope_ts = np.nan\n",
    "            d_s_ts = np.nan\n",
    "        rows.append({'b': b_idx, 'lambda_max': lm, 'levina_mle': levina_val,\n",
    "                     'theilsen_slope': float(slope_ts) if np.isfinite(slope_ts) else np.nan,\n",
    "                     'theilsen_d_s': float(d_s_ts) if np.isfinite(d_s_ts) else np.nan,\n",
    "                     'n_points_fit': n_points, 'fit_ok': bool(fit_ok)})\n",
    "    print(f\"b={b_idx}: levina={levina_val:.3f}, eigvals={len(eigvals)}, lam_unique={len(lam_vals)}\")\n",
    "\n",
    "theilsen_df = pd.DataFrame(rows)\n",
    "theilsen_fp = os.path.join(out_dir, 'paired_levina_spectral_theilsen_raw.csv')\n",
    "theilsen_df.to_csv(theilsen_fp, index=False)\n",
    "print(\"Saved Theil-Sen raw:\", theilsen_fp)\n",
    "\n",
    "# --- For each lambda_max, perform paired tests between levina_mle and theilsen_d_s ---\n",
    "test_rows = []\n",
    "for lm in lambda_max_list:\n",
    "    subset = theilsen_df[theilsen_df['lambda_max'] == lm].dropna(subset=['levina_mle', 'theilsen_d_s'])\n",
    "    n_pairs = len(subset)\n",
    "    if n_pairs == 0:\n",
    "        test_rows.append({'lambda_max': lm, 'n_pairs': 0})\n",
    "        continue\n",
    "    lev = subset['levina_mle'].values\n",
    "    ds = subset['theilsen_d_s'].values\n",
    "    diff = lev - ds\n",
    "    med_lev = float(np.median(lev))\n",
    "    med_ds = float(np.median(ds))\n",
    "    mean_diff = float(np.mean(diff))\n",
    "    std_diff = float(np.std(diff, ddof=1))\n",
    "    try:\n",
    "        wil = stats.wilcoxon(lev, ds, alternative='two-sided', zero_method='wilcox')\n",
    "        wil_stat, wil_p = float(wil.statistic), float(wil.pvalue)\n",
    "    except Exception:\n",
    "        wil_stat, wil_p = np.nan, np.nan\n",
    "    try:\n",
    "        t = stats.ttest_rel(lev, ds, nan_policy='omit')\n",
    "        t_stat, t_p = float(t.statistic), float(t.pvalue)\n",
    "    except Exception:\n",
    "        t_stat, t_p = np.nan, np.nan\n",
    "    try:\n",
    "        rho, rho_p = stats.spearmanr(lev, ds, nan_policy='omit')\n",
    "        rho, rho_p = float(rho), float(rho_p)\n",
    "    except Exception:\n",
    "        rho, rho_p = np.nan, np.nan\n",
    "    test_rows.append({\n",
    "        'lambda_max': lm, 'n_pairs': int(n_pairs),\n",
    "        'median_levina': med_lev, 'median_theilsen_d_s': med_ds,\n",
    "        'mean_diff': mean_diff, 'std_diff': std_diff,\n",
    "        'wilcoxon_stat': wil_stat, 'wilcoxon_p': wil_p,\n",
    "        'paired_t_stat': t_stat, 'paired_t_p': t_p,\n",
    "        'spearman_rho': rho, 'spearman_p': rho_p\n",
    "    })\n",
    "\n",
    "tests_df = pd.DataFrame(test_rows)\n",
    "tests_fp = os.path.join(out_dir, 'paired_levina_spectral_theilsen_tests_summary.csv')\n",
    "tests_df.to_csv(tests_fp, index=False)\n",
    "print(\"Saved tests summary:\", tests_fp)\n",
    "\n",
    "# --- Save plots: scatter annotated and boxplot differences ---\n",
    "for lm in lambda_max_list:\n",
    "    subset = theilsen_df[theilsen_df['lambda_max'] == lm].dropna(subset=['levina_mle', 'theilsen_d_s'])\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(subset['levina_mle'], subset['theilsen_d_s'], alpha=0.7, s=18)\n",
    "    if not subset.empty:\n",
    "        mn = min(subset['levina_mle'].min(), subset['theilsen_d_s'].min())\n",
    "        mx = max(subset['levina_mle'].max(), subset['theilsen_d_s'].max())\n",
    "    else:\n",
    "        mn, mx = 0, 1\n",
    "    plt.plot([mn, mx], [mn, mx], color='gray', linestyle='--', linewidth=1)\n",
    "    plt.xlabel('Levina-Bickel MLE (m_hat)')\n",
    "    plt.ylabel('Theil-Sen spectral d_s')\n",
    "    plt.title(f'Levina vs Theil-Sen spectral (lambda_max={lm})')\n",
    "    row = tests_df[tests_df['lambda_max'] == lm]\n",
    "    if not row.empty:\n",
    "        r = row.iloc[0]\n",
    "        ann = (f\"n={int(r['n_pairs'])}\\nmedian_lev={r['median_levina']:.3f}\\nmedian_ds={r['median_theilsen_d_s']:.3f}\\n\"\n",
    "               f\"Wilcoxon p={r['wilcoxon_p']:.2e}\\npaired t p={r['paired_t_p']:.2e}\\nSpearman rho={r['spearman_rho']:.2f}\")\n",
    "        plt.gca().text(0.02, 0.98, ann, transform=plt.gca().transAxes, fontsize=8, va='top', ha='left',\n",
    "                       bbox=dict(facecolor='white', alpha=0.85, edgecolor='none'))\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f'paired_scatter_lambda_{lm}_theilsen.png'), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,3.5))\n",
    "data = []\n",
    "labels = []\n",
    "p_texts = []\n",
    "for lm in lambda_max_list:\n",
    "    subset = theilsen_df[theilsen_df['lambda_max'] == lm].dropna(subset=['levina_mle', 'theilsen_d_s'])\n",
    "    diff = (subset['levina_mle'] - subset['theilsen_d_s']).values\n",
    "    data.append(diff)\n",
    "    labels.append(str(lm))\n",
    "    row = tests_df[tests_df['lambda_max'] == lm]\n",
    "    pval = float(row['wilcoxon_p'].values[0]) if not row.empty else np.nan\n",
    "    p_texts.append(f\"p={pval:.1e}\" if np.isfinite(pval) else \"p=NA\")\n",
    "\n",
    "plt.boxplot(data, labels=labels, showfliers=False)\n",
    "ymax = plt.ylim()[1]\n",
    "for xi, txt in enumerate(p_texts, start=1):\n",
    "    plt.text(xi, ymax*0.98, txt, ha='center', va='top', fontsize=8)\n",
    "plt.xlabel('lambda_max')\n",
    "plt.ylabel('Levina - Theil-Sen d_s')\n",
    "plt.title('Paired differences (Levina - Theil-Sen) with Wilcoxon p-values')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, 'paired_diff_boxplot_theilsen.png'), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved plots and CSVs to\", out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865f6649",
   "metadata": {},
   "source": [
    "Résumé essentiel des résultats\n",
    "\n",
    "Les estimations Levina (m_hat) sont ≈ 7.94 (médiane) tandis que les d_s spectral recalculés (d_s = 2·slope via Theil‑Sen) sont bien plus faibles : médianes ≈ 0.83 (λ_max=0.1), 1.56 (λ_max=0.2), 3.19 (λ_max=0.4) — divergence massive et systématique.\n",
    "\n",
    "Les tests appariés (Wilcoxon + t) donnent p ≪ 0.001 pour toutes les λ_max : la différence Levina − d_s_TheilSen est hautement significative.\n",
    "\n",
    "Conclusion immédiate : les deux estimateurs mesurent des quantités numériquement et conceptuellement différentes sur tes choix actuels (échelle λ, définition du fit, conversion en d_s), donc on n’a pas une « erreur aléatoire » mais une vraie incompatibilité méthodologique.\n",
    "\n",
    "Diagnostic rapide de pourquoi ça diverge\n",
    "Définitions différentes : Levina‑Bickel retourne un estimateur d dimension intrinsèque (m_hat) basé sur voisins locaux; d_s spectral = 2·pente(log N(λ) vs log λ) mesure la loi d’échelle spectrale — ils peuvent être conceptuellement non équivalents selon construction/normalisation et plage λ.\n",
    "\n",
    "Plage λ et densité de points : Theil‑Sen appliqué sur λ ≤ 0.1..0.4 donne pentes qui croissent fortement avec λ_max — résultat très dépendant de la plage utilisée.\n",
    "\n",
    "Influence des petits λ / points isolés : précédemment on a vu qu’un point influent changeait énormément la pente OLS ; même avec Theil‑Sen, choisir la plage de λ et le pré‑filtrage produit des différences fortes.\n",
    "\n",
    "Échelle numérique : Levina m_hat ≈ 8 vs d_s spectral <~3 → probablement absence d’isomorphisme direct entre ces valeurs dans ta pipeline (facteur d’échelle ou définition différente)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59c876",
   "metadata": {},
   "source": [
    "Cellule Python — Lister et visualiser les K bootstraps avec plus grand écart Levina − Theil‑Sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447677cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved top-K summary and per-boot diagnostics to results/topK_discrepancy_inspect\n",
      "Fichiers produits (résumé):\n",
      "- b_009_lambda_0.2_counting.csv\n",
      "- b_009_lambda_0.2_spectral_diagnostic.png\n",
      "- b_015_lambda_0.2_counting.csv\n",
      "- b_015_lambda_0.2_spectral_diagnostic.png\n",
      "- b_025_lambda_0.2_counting.csv\n",
      "- b_025_lambda_0.2_spectral_diagnostic.png\n",
      "- b_026_lambda_0.2_counting.csv\n",
      "- b_026_lambda_0.2_spectral_diagnostic.png\n",
      "- b_064_lambda_0.2_counting.csv\n",
      "- b_064_lambda_0.2_spectral_diagnostic.png\n",
      "- b_124_lambda_0.2_counting.csv\n",
      "- b_124_lambda_0.2_spectral_diagnostic.png\n",
      "- b_129_lambda_0.2_counting.csv\n",
      "- b_129_lambda_0.2_spectral_diagnostic.png\n",
      "- b_137_lambda_0.2_counting.csv\n",
      "- b_137_lambda_0.2_spectral_diagnostic.png\n",
      "- b_140_lambda_0.2_counting.csv\n",
      "- b_140_lambda_0.2_spectral_diagnostic.png\n",
      "- b_150_lambda_0.2_counting.csv\n",
      "- b_150_lambda_0.2_spectral_diagnostic.png\n",
      "- top_10_discrepancy_inspection_lambda_0.2.csv\n",
      "- top_10_discrepancy_summary_lambda_0.2.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell: Inspecter top-K bootstraps avec plus grand |levina_mle - theilsen_d_s|\n",
    "# Produit pour chaque b sélectionné : CSV résumé, plot log-log N(lambda) avec Theil-Sen fit,\n",
    "# annotation des points influents (Cook proxy), et sauvegarde des résultats.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import TheilSenRegressor, LinearRegression\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paramètres (adapter si besoin)\n",
    "theilsen_raw_fp = 'results/paired_levina_spectral_theilsen/paired_levina_spectral_theilsen_raw.csv'\n",
    "levina_info_fp = 'results/levina_bickel_boot_samples.csv'  # pour info si besoin\n",
    "csv_out_dir = 'results/topK_discrepancy_inspect'\n",
    "top_k = 10\n",
    "k_neighbors = 10\n",
    "n_eig = 400\n",
    "lambda_max_inspect = 0.2   # plage sur laquelle Theil-Sen a été calculé (doit correspondre)\n",
    "min_points_for_fit = 4\n",
    "os.makedirs(csv_out_dir, exist_ok=True)\n",
    "\n",
    "# Utilitaires (levegage + Cook approximation on log-log fit)\n",
    "def compute_leverage_and_cooks(x_log, resid, mse):\n",
    "    n = len(x_log)\n",
    "    x = x_log\n",
    "    xbar = np.mean(x)\n",
    "    Sxx = np.sum((x - xbar)**2)\n",
    "    h = 1.0/n + ((x - xbar)**2)/Sxx if Sxx > 0 else np.repeat(1.0/n, n)\n",
    "    p = 2\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        cooks = (resid**2) / (p * mse) * (h / (1 - h)**2)\n",
    "    return h, cooks\n",
    "\n",
    "def build_laplacian_eigs(X_points, k_neighbors, n_eig):\n",
    "    n_nodes_local = X_points.shape[0]\n",
    "    nbrs = NearestNeighbors(n_neighbors=min(k_neighbors + 1, n_nodes_local), algorithm='auto').fit(X_points)\n",
    "    distances, indices = nbrs.kneighbors(X_points)\n",
    "    adj = sparse.lil_matrix((n_nodes_local, n_nodes_local), dtype=np.float32)\n",
    "    for i in range(n_nodes_local):\n",
    "        for j in indices[i, 1:]:\n",
    "            adj[i, j] = 1.0\n",
    "            adj[j, i] = 1.0\n",
    "    adj = adj.tocsr()\n",
    "    deg = np.array(adj.sum(axis=1)).flatten()\n",
    "    deg[deg == 0] = 1.0\n",
    "    D_inv_sqrt = sparse.diags(1.0 / np.sqrt(deg))\n",
    "    I = sparse.identity(n_nodes_local, format='csr')\n",
    "    L_norm = I - D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "    n_eig_local = min(n_eig, n_nodes_local - 1)\n",
    "    try:\n",
    "        eigvals, _ = eigsh(L_norm, k=n_eig_local, which='SM', tol=1e-6, maxiter=5000)\n",
    "    except Exception:\n",
    "        try:\n",
    "            from scipy.linalg import eigh\n",
    "            Ld = L_norm.toarray()\n",
    "            eigvals_all = eigh(Ld, eigvals_only=True)\n",
    "            eigvals = np.sort(eigvals_all)[:n_eig_local]\n",
    "        except Exception as e:\n",
    "            print(\"Eigen decomposition failed:\", e)\n",
    "            return None\n",
    "    return np.sort(eigvals)\n",
    "\n",
    "def spectral_counting(eigvals):\n",
    "    eps = 1e-12\n",
    "    lams = eigvals[eigvals > eps]\n",
    "    lam_vals = np.unique(lams)\n",
    "    N_vals = np.array([np.searchsorted(lams, lam, side='right') for lam in lam_vals])\n",
    "    return lam_vals, N_vals\n",
    "\n",
    "# Charger les résultats Theil-Sen déjà calculés\n",
    "if not os.path.exists(theilsen_raw_fp):\n",
    "    raise RuntimeError(f\"Fichier introuvable: {theilsen_raw_fp}\")\n",
    "\n",
    "df_ts = pd.read_csv(theilsen_raw_fp)\n",
    "\n",
    "# Calculer l'écart absolu et trier\n",
    "df_ts['abs_diff'] = np.abs(df_ts['levina_mle'] - df_ts['theilsen_d_s'])\n",
    "# Restreindre à lambda_max inspecté\n",
    "df_sel = df_ts[df_ts['lambda_max'] == lambda_max_inspect].copy()\n",
    "if df_sel.empty:\n",
    "    raise RuntimeError(f\"Aucune ligne pour lambda_max={lambda_max_inspect} dans {theilsen_raw_fp}\")\n",
    "\n",
    "df_top = df_sel.sort_values('abs_diff', ascending=False).head(top_k)\n",
    "df_top.to_csv(os.path.join(csv_out_dir, f'top_{top_k}_discrepancy_summary_lambda_{lambda_max_inspect}.csv'), index=False)\n",
    "\n",
    "# Load embedding and regenerate bootstrap indices if needed (to plot spectral counting)\n",
    "# Try to infer embedding parameters from existing files; fall back to common defaults\n",
    "csv_series_path = 'data/sunspots_raw/Sunspots.csv'\n",
    "if not os.path.exists(csv_series_path):\n",
    "    print(\"Attention: série de temps source non trouvée pour recalcul des spectres:\", csv_series_path)\n",
    "    recompute_eigs = False\n",
    "else:\n",
    "    recompute_eigs = True\n",
    "    # small embedding settings — match those used précédemment if possible\n",
    "    embedding_dim = 10\n",
    "    tau = 1\n",
    "    subsample_frac = 0.6\n",
    "    rng_seed = 42\n",
    "    # build embedding\n",
    "    df0 = pd.read_csv(csv_series_path)\n",
    "    value_col_candidates = ['Number', 'Total Sunspot', 'Total Sunspot Number', 'Monthly Mean']\n",
    "    col = next((c for c in value_col_candidates if c in df0.columns), None)\n",
    "    if col is None:\n",
    "        numeric_cols = df0.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if not numeric_cols:\n",
    "            recompute_eigs = False\n",
    "        else:\n",
    "            col = numeric_cols[-1]\n",
    "    if recompute_eigs:\n",
    "        series = pd.to_numeric(df0[col], errors='coerce').dropna().values\n",
    "        # Takens embed\n",
    "        m = len(series) - (embedding_dim - 1) * tau\n",
    "        if m <= 0:\n",
    "            recompute_eigs = False\n",
    "        else:\n",
    "            X_full = np.empty((m, embedding_dim))\n",
    "            for ii in range(embedding_dim):\n",
    "                X_full[:, ii] = series[ii * tau : ii * tau + m]\n",
    "            n_nodes = X_full.shape[0]\n",
    "            # deterministic bootstrap indices (must match prior seed/frac if same code)\n",
    "            rng = np.random.default_rng(rng_seed)\n",
    "            indices_list = [rng.choice(np.arange(n_nodes), size=max(120, int(np.floor(subsample_frac * n_nodes))), replace=False)\n",
    "                            for _ in range(int(df_ts['b'].max()))]\n",
    "\n",
    "# For each top b, regenerate spectrum plot and annotate influential points on the lambda_max_inspect fit\n",
    "rows_inspect = []\n",
    "for i, row in df_top.iterrows():\n",
    "    b = int(row['b'])\n",
    "    levina_val = float(row['levina_mle'])\n",
    "    d_s_val = float(row['theilsen_d_s'])\n",
    "    abs_diff = float(row['abs_diff'])\n",
    "    out_prefix = os.path.join(csv_out_dir, f'b_{b:03d}_lambda_{lambda_max_inspect}')\n",
    "    # If we can recompute eigs, do full plotting; otherwise, create a minimal scatter using available data\n",
    "    if recompute_eigs:\n",
    "        idx = indices_list[b-1]\n",
    "        X_sub = X_full[idx, :]\n",
    "        eigvals = build_laplacian_eigs(X_sub, k_neighbors, n_eig)\n",
    "        if eigvals is None:\n",
    "            print(f\"b={b}: eig computation failed; skipping detailed plot\")\n",
    "            rows_inspect.append({'b': b, 'levina_mle': levina_val, 'theilsen_d_s': d_s_val, 'abs_diff': abs_diff, 'n_lambda': np.nan})\n",
    "            continue\n",
    "        lam_vals, N_vals = spectral_counting(eigvals)\n",
    "        # Fit Theil-Sen on lam <= lambda_max_inspect (recompute diagnostics)\n",
    "        mask = lam_vals <= lambda_max_inspect\n",
    "        lam_fit = lam_vals[mask]\n",
    "        N_fit = N_vals[mask]\n",
    "        n_points = len(lam_fit)\n",
    "        fit_ok = n_points >= min_points_for_fit\n",
    "        if fit_ok:\n",
    "            x_log = np.log(lam_fit)\n",
    "            y_log = np.log(N_fit)\n",
    "            # OLS for diagnostics\n",
    "            lr = LinearRegression().fit(x_log.reshape(-1,1), y_log)\n",
    "            y_pred = lr.predict(x_log.reshape(-1,1))\n",
    "            resid = y_log - y_pred\n",
    "            mse = np.sum(resid**2) / max(len(x_log)-2,1)\n",
    "            h, cooks = compute_leverage_and_cooks(x_log, resid, mse)\n",
    "            cook_thresh = 4.0 / max(1, len(x_log))\n",
    "            infl_idx = np.where(cooks > cook_thresh)[0]\n",
    "            # Theil-Sen fit for plotting\n",
    "            try:\n",
    "                ts = TheilSenRegressor(random_state=0).fit(x_log.reshape(-1,1), y_log)\n",
    "                slope_ts = float(ts.coef_[0])\n",
    "                intercept_ts = float(ts.intercept_)\n",
    "            except Exception:\n",
    "                slope_ts = np.nan\n",
    "                intercept_ts = np.nan\n",
    "            # Save raw lam/N for this b\n",
    "            pd.DataFrame({'lambda': lam_vals, 'N_lambda': N_vals}).to_csv(out_prefix + '_counting.csv', index=False)\n",
    "            # Plot log-log with fits and annotations\n",
    "            plt.figure(figsize=(6,4))\n",
    "            ax = plt.gca()\n",
    "            ax.loglog(lam_vals, N_vals, 'o', ms=4, alpha=0.6, label='N(lambda)')\n",
    "            xline = np.linspace(lam_fit.min() if fit_ok else lam_vals.min(), lam_fit.max() if fit_ok else lam_vals.max(), 200)\n",
    "            # plot OLS fit over lam_fit if available\n",
    "            if fit_ok:\n",
    "                ax.loglog(xline, np.exp(intercept_ts) * xline**(slope_ts), '-', color='C2', lw=1.8, label=f'Theil-Sen slope={slope_ts:.3f}')\n",
    "            ax.set_xlabel('lambda (eigenvalue)')\n",
    "            ax.set_ylabel('N(lambda)')\n",
    "            ax.set_title(f'b={b} Levina={levina_val:.3f} Theil-Sen d_s={d_s_val:.3f}')\n",
    "            # annotate influential points\n",
    "            if fit_ok and infl_idx.size>0:\n",
    "                for ii in infl_idx:\n",
    "                    lam_pt = lam_fit[ii]\n",
    "                    N_pt = N_fit[ii]\n",
    "                    ax.loglog([lam_pt],[N_pt],'s', color='red', ms=6)\n",
    "                    ax.annotate(str(ii+1), xy=(lam_pt, N_pt), xytext=(5,-6), textcoords='offset points', color='red', fontsize=7)\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(alpha=0.3, which='both')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(out_prefix + '_spectral_diagnostic.png', dpi=150)\n",
    "            plt.close()\n",
    "            rows_inspect.append({'b': b, 'levina_mle': levina_val, 'theilsen_d_s': d_s_val, 'abs_diff': abs_diff, 'n_lambda': int(len(lam_vals)), 'n_points_fit': int(n_points), 'n_influential': int(infl_idx.size)})\n",
    "        else:\n",
    "            # save raw counting CSV and note insufficient fit points\n",
    "            pd.DataFrame({'lambda': lam_vals, 'N_lambda': N_vals}).to_csv(out_prefix + '_counting.csv', index=False)\n",
    "            rows_inspect.append({'b': b, 'levina_mle': levina_val, 'theilsen_d_s': d_s_val, 'abs_diff': abs_diff, 'n_lambda': int(len(lam_vals)), 'n_points_fit': int(n_points), 'n_influential': 0})\n",
    "            print(f\"b={b}: insufficient fit points (n_points={n_points})\")\n",
    "    else:\n",
    "        # fallback: write only summary row if recompute not possible\n",
    "        rows_inspect.append({'b': b, 'levina_mle': levina_val, 'theilsen_d_s': d_s_val, 'abs_diff': abs_diff, 'n_lambda': np.nan, 'n_points_fit': np.nan, 'n_influential': np.nan})\n",
    "\n",
    "# Save inspection table\n",
    "inspect_df = pd.DataFrame(rows_inspect)\n",
    "inspect_df.to_csv(os.path.join(csv_out_dir, f'top_{top_k}_discrepancy_inspection_lambda_{lambda_max_inspect}.csv'), index=False)\n",
    "\n",
    "print(\"Saved top-K summary and per-boot diagnostics to\", csv_out_dir)\n",
    "print(\"Fichiers produits (résumé):\")\n",
    "for f in sorted(os.listdir(csv_out_dir))[:50]:\n",
    "    print(\"-\", f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843049a",
   "metadata": {},
   "source": [
    "Observations clefs (rapide)\n",
    "\n",
    "Pour les 10 bootstraps les plus discordants (top_10 CSV), Theil‑Sen donne des pentes autour de 0.69–0.76 → d_s ≈ 1.38–1.52, alors que Levina m_hat ≈ 8.0. La différence médiane levina − d_s ≈ 6.5 (ordre de grandeur constant).\n",
    "\n",
    "Les plots (ex. b=9,15,25,26,64,124,129,137,140,150) montrent :\n",
    "\n",
    "une plage log‑log globalement linéaire sur λ ≤ 0.2 ;\n",
    "\n",
    "la droite Theil‑Sen suit bien la tendance centrale des points (pente robuste ≈ 0.72),\n",
    "\n",
    "un point marqué «1» très à gauche (λ très petit) visible dans tous les diagnostics : c’est quasi systématiquement le petit λ isolé qui tire la courbe et qui, selon la méthode (OLS vs robuste), change fortement la pente estimée.\n",
    "\n",
    "Diagnostics numériques déjà produits : pour lambda_max=0.2, top_10 abs_diff ≈ 6.52–6.65 ; n_points_fit ≈ 15–16 (fits stables en nombre de points).\n",
    "\n",
    "Interprétation concise\n",
    "\n",
    "Ce n’est pas un bug numérique mineur : c’est une incompatibilité méthodologique/échelle. Levina‑Bickel et la pente spectrale (même robuste) mesurent des choses différentes ; la pente spectrale dépend fortement de la plage λ et des points extrêmes (petits λ).\n",
    "\n",
    "Theil‑Sen réduit la sensibilité aux outliers par rapport à OLS sans influent, mais la valeur spectrale reste << Levina. Donc il n’y a pas « une méthode correcte » à priori — il faut définir l’objet qu’on veut estimer et justifier la méthode choisie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9050c54",
   "metadata": {},
   "source": [
    "Cell Python — Effet d’exclure les k plus petits lambda (k = 0..3) sur d_s (Theil‑Sen) pour chaque bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86254a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b=1: lam_total=17\n",
      "b=2: lam_total=17\n",
      "b=3: lam_total=16\n",
      "b=4: lam_total=17\n",
      "b=5: lam_total=17\n",
      "b=6: lam_total=17\n",
      "b=7: lam_total=17\n",
      "b=8: lam_total=18\n",
      "b=9: lam_total=16\n",
      "b=10: lam_total=16\n",
      "b=11: lam_total=18\n",
      "b=12: lam_total=16\n",
      "b=13: lam_total=17\n",
      "b=14: lam_total=17\n",
      "b=15: lam_total=16\n",
      "b=16: lam_total=16\n",
      "b=17: lam_total=17\n",
      "b=18: lam_total=17\n",
      "b=19: lam_total=18\n",
      "b=20: lam_total=17\n",
      "b=21: lam_total=16\n",
      "b=22: lam_total=16\n",
      "b=23: lam_total=16\n",
      "b=24: lam_total=17\n",
      "b=25: lam_total=16\n",
      "b=26: lam_total=16\n",
      "b=27: lam_total=17\n",
      "b=28: lam_total=16\n",
      "b=29: lam_total=17\n",
      "b=30: lam_total=17\n",
      "b=31: lam_total=17\n",
      "b=32: lam_total=16\n",
      "b=33: lam_total=18\n",
      "b=34: lam_total=16\n",
      "b=35: lam_total=17\n",
      "b=36: lam_total=16\n",
      "b=37: lam_total=16\n",
      "b=38: lam_total=15\n",
      "b=39: lam_total=16\n",
      "b=40: lam_total=17\n",
      "b=41: lam_total=17\n",
      "b=42: lam_total=17\n",
      "b=43: lam_total=17\n",
      "b=44: lam_total=16\n",
      "b=45: lam_total=16\n",
      "b=46: lam_total=16\n",
      "b=47: lam_total=16\n",
      "b=48: lam_total=16\n",
      "b=49: lam_total=17\n",
      "b=50: lam_total=16\n",
      "b=51: lam_total=16\n",
      "b=52: lam_total=18\n",
      "b=53: lam_total=16\n",
      "b=54: lam_total=16\n",
      "b=55: lam_total=17\n",
      "b=56: lam_total=16\n",
      "b=57: lam_total=17\n",
      "b=58: lam_total=16\n",
      "b=59: lam_total=17\n",
      "b=60: lam_total=16\n",
      "b=61: lam_total=16\n",
      "b=62: lam_total=17\n",
      "b=63: lam_total=16\n",
      "b=64: lam_total=16\n",
      "b=65: lam_total=17\n",
      "b=66: lam_total=17\n",
      "b=67: lam_total=15\n",
      "b=68: lam_total=16\n",
      "b=69: lam_total=17\n",
      "b=70: lam_total=17\n",
      "b=71: lam_total=17\n",
      "b=72: lam_total=17\n",
      "b=73: lam_total=16\n",
      "b=74: lam_total=17\n",
      "b=75: lam_total=17\n",
      "b=76: lam_total=17\n",
      "b=77: lam_total=16\n",
      "b=78: lam_total=16\n",
      "b=79: lam_total=16\n",
      "b=80: lam_total=16\n",
      "b=81: lam_total=16\n",
      "b=82: lam_total=16\n",
      "b=83: lam_total=17\n",
      "b=84: lam_total=17\n",
      "b=85: lam_total=16\n",
      "b=86: lam_total=16\n",
      "b=87: lam_total=17\n",
      "b=88: lam_total=16\n",
      "b=89: lam_total=17\n",
      "b=90: lam_total=16\n",
      "b=91: lam_total=17\n",
      "b=92: lam_total=17\n",
      "b=93: lam_total=16\n",
      "b=94: lam_total=16\n",
      "b=95: lam_total=17\n",
      "b=96: lam_total=17\n",
      "b=97: lam_total=17\n",
      "b=98: lam_total=17\n",
      "b=99: lam_total=17\n",
      "b=100: lam_total=16\n",
      "b=101: lam_total=16\n",
      "b=102: lam_total=16\n",
      "b=103: lam_total=16\n",
      "b=104: lam_total=17\n",
      "b=105: lam_total=15\n",
      "b=106: lam_total=16\n",
      "b=107: lam_total=17\n",
      "b=108: lam_total=17\n",
      "b=109: lam_total=16\n",
      "b=110: lam_total=16\n",
      "b=111: lam_total=17\n",
      "b=112: lam_total=15\n",
      "b=113: lam_total=17\n",
      "b=114: lam_total=16\n",
      "b=115: lam_total=16\n",
      "b=116: lam_total=16\n",
      "b=117: lam_total=16\n",
      "b=118: lam_total=16\n",
      "b=119: lam_total=16\n",
      "b=120: lam_total=17\n",
      "b=121: lam_total=16\n",
      "b=122: lam_total=17\n",
      "b=123: lam_total=16\n",
      "b=124: lam_total=15\n",
      "b=125: lam_total=16\n",
      "b=126: lam_total=17\n",
      "b=127: lam_total=17\n",
      "b=128: lam_total=16\n",
      "b=129: lam_total=16\n",
      "b=130: lam_total=16\n",
      "b=131: lam_total=16\n",
      "b=132: lam_total=16\n",
      "b=133: lam_total=16\n",
      "b=134: lam_total=16\n",
      "b=135: lam_total=17\n",
      "b=136: lam_total=17\n",
      "b=137: lam_total=16\n",
      "b=138: lam_total=17\n",
      "b=139: lam_total=16\n",
      "b=140: lam_total=15\n",
      "b=141: lam_total=17\n",
      "b=142: lam_total=17\n",
      "b=143: lam_total=17\n",
      "b=144: lam_total=16\n",
      "b=145: lam_total=17\n",
      "b=146: lam_total=16\n",
      "b=147: lam_total=17\n",
      "b=148: lam_total=17\n",
      "b=149: lam_total=17\n",
      "b=150: lam_total=16\n",
      "Saved per-b results to results/ds_remove_small_lambda\\theilsen_ds_remove_small_lambda_per_b.csv\n",
      "Saved wide table to results/ds_remove_small_lambda\\theilsen_ds_remove_small_lambda_wide.csv\n",
      "Saved plot: results/ds_remove_small_lambda\\ds_vs_k_plot.png\n",
      "Found 0 bootstraps with |d_s(k=1)-d_s(k=0)| > 0.2; saved to results/ds_remove_small_lambda\\sensitive_bootstraps_k0_k1.csv\n",
      "Done. Files in results/ds_remove_small_lambda\n"
     ]
    }
   ],
   "source": [
    "# Cell: recompute Theil-Sen d_s removing k smallest lambda (k=0..3) for each bootstrap b,\n",
    "# save per-b table (d_s_k0..k3) and aggregated plot \"d_s vs k\" and list of sensitive b (Δd_s > thresh).\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "\n",
    "# Parameters (edit if desired)\n",
    "csv_series_path = 'data/sunspots_raw/Sunspots.csv'\n",
    "levina_samples_path = 'results/levina_bickel_boot_samples.csv'   # must contain columns 'b' and 'levina_mle'\n",
    "out_dir = 'results/ds_remove_small_lambda'\n",
    "embedding_dim = 10\n",
    "tau = 1\n",
    "subsample_frac = 0.6\n",
    "rng_seed = 42\n",
    "k_values = [0, 1, 2, 3]           # number of smallest lambda values to drop before fitting\n",
    "lambda_max = 0.2                  # same lambda_max used previously for comparability\n",
    "k_neighbors = 10\n",
    "n_eig = 400\n",
    "min_points_for_fit = 4\n",
    "sensitive_delta = 0.2             # threshold for calling a bootstrap \"sensitive\" (change in d_s)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Utilities\n",
    "def takens_embed(x, dim, tau):\n",
    "    m = len(x) - (dim - 1) * tau\n",
    "    if m <= 0:\n",
    "        return None\n",
    "    embed = np.empty((m, dim))\n",
    "    for i in range(dim):\n",
    "        embed[:, i] = x[i * tau : i * tau + m]\n",
    "    return embed\n",
    "\n",
    "def build_laplacian_eigs(X_points, k_neighbors, n_eig):\n",
    "    n_nodes_local = X_points.shape[0]\n",
    "    nbrs = NearestNeighbors(n_neighbors=min(k_neighbors + 1, n_nodes_local), algorithm='auto').fit(X_points)\n",
    "    distances, indices = nbrs.kneighbors(X_points)\n",
    "    adj = sparse.lil_matrix((n_nodes_local, n_nodes_local), dtype=np.float32)\n",
    "    for i in range(n_nodes_local):\n",
    "        for j in indices[i, 1:]:\n",
    "            adj[i, j] = 1.0\n",
    "            adj[j, i] = 1.0\n",
    "    adj = adj.tocsr()\n",
    "    deg = np.array(adj.sum(axis=1)).flatten()\n",
    "    deg[deg == 0] = 1.0\n",
    "    D_inv_sqrt = sparse.diags(1.0 / np.sqrt(deg))\n",
    "    I = sparse.identity(n_nodes_local, format='csr')\n",
    "    L_norm = I - D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "    n_eig_local = min(n_eig, n_nodes_local - 1)\n",
    "    try:\n",
    "        eigvals, _ = eigsh(L_norm, k=n_eig_local, which='SM', tol=1e-6, maxiter=5000)\n",
    "    except Exception:\n",
    "        try:\n",
    "            from scipy.linalg import eigh\n",
    "            Ld = L_norm.toarray()\n",
    "            eigvals_all = eigh(Ld, eigvals_only=True)\n",
    "            eigvals = np.sort(eigvals_all)[:n_eig_local]\n",
    "        except Exception as e:\n",
    "            print(\"Eigen decomposition failed:\", e)\n",
    "            return None\n",
    "    return np.sort(eigvals)\n",
    "\n",
    "def spectral_counting(eigvals):\n",
    "    eps = 1e-12\n",
    "    lams = eigvals[eigvals > eps]\n",
    "    lam_vals = np.unique(lams)\n",
    "    N_vals = np.array([np.searchsorted(lams, lam, side='right') for lam in lam_vals])\n",
    "    return lam_vals, N_vals\n",
    "\n",
    "def theilsen_on_loglog(lam_vals, N_vals):\n",
    "    if len(lam_vals) < 2:\n",
    "        return np.nan\n",
    "    x = np.log(lam_vals).reshape(-1,1)\n",
    "    y = np.log(N_vals)\n",
    "    if len(x) < 3:\n",
    "        slope, intercept, r, p, se = stats.linregress(x.flatten(), y)\n",
    "        return float(slope)\n",
    "    ts = TheilSenRegressor(random_state=0)\n",
    "    ts.fit(x, y)\n",
    "    return float(ts.coef_[0])\n",
    "\n",
    "# Load levina samples to get bootstrap list and levina_mle\n",
    "if not os.path.exists(levina_samples_path):\n",
    "    raise RuntimeError(f\"Levina samples not found: {levina_samples_path}\")\n",
    "lev_df = pd.read_csv(levina_samples_path)\n",
    "if 'b' not in lev_df.columns:\n",
    "    raise RuntimeError(\"levina_bickel_boot_samples.csv must contain column 'b'\")\n",
    "if 'levina_mle' not in lev_df.columns:\n",
    "    alt = next((c for c in lev_df.columns if 'levina' in c or 'm_hat' in c), None)\n",
    "    if alt is None:\n",
    "        raise RuntimeError(\"levina_bickel_boot_samples.csv missing 'levina_mle' column\")\n",
    "    lev_df = lev_df.rename(columns={alt: 'levina_mle'})\n",
    "\n",
    "# Build embedding once\n",
    "if not os.path.exists(csv_series_path):\n",
    "    raise RuntimeError(f\"Time series CSV not found: {csv_series_path}\")\n",
    "df0 = pd.read_csv(csv_series_path)\n",
    "value_col_candidates = ['Number', 'Total Sunspot', 'Total Sunspot Number', 'Monthly Mean']\n",
    "col = next((c for c in value_col_candidates if c in df0.columns), None)\n",
    "if col is None:\n",
    "    numeric_cols = df0.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not numeric_cols:\n",
    "        raise RuntimeError(\"No numeric column found in CSV.\")\n",
    "    col = numeric_cols[-1]\n",
    "series = pd.to_numeric(df0[col], errors='coerce').dropna().values\n",
    "X_full = takens_embed(series, embedding_dim, tau)\n",
    "if X_full is None:\n",
    "    raise RuntimeError(\"Embedding too short for given embedding_dim/tau.\")\n",
    "n_nodes = X_full.shape[0]\n",
    "\n",
    "# Recreate deterministic bootstrap indices (must match prior runs)\n",
    "n_boot = int(lev_df['b'].max())\n",
    "rng = default_rng(rng_seed)\n",
    "indices_list = [rng.choice(np.arange(n_nodes), size=max(120, int(np.floor(subsample_frac * n_nodes))), replace=False)\n",
    "                for _ in range(n_boot)]\n",
    "\n",
    "# Iterate bootstraps and k values\n",
    "rows = []\n",
    "for b_val in sorted(lev_df['b'].unique()):\n",
    "    b = int(b_val)\n",
    "    if b < 1 or b > len(indices_list):\n",
    "        print(f\"Skipping b={b} (index out of range)\")\n",
    "        continue\n",
    "    levina_val = float(lev_df[lev_df['b'] == b]['levina_mle'].iloc[0])\n",
    "    idx = indices_list[b-1]\n",
    "    X_sub = X_full[idx, :]\n",
    "    eigvals = build_laplacian_eigs(X_sub, k_neighbors, n_eig)\n",
    "    if eigvals is None:\n",
    "        for k in k_values:\n",
    "            rows.append({'b': b, 'levina_mle': levina_val, 'k': k, 'n_lambda_total': np.nan, 'n_points_fit': 0, 'theilsen_slope': np.nan, 'theilsen_d_s': np.nan, 'fit_ok': False})\n",
    "        continue\n",
    "    lam_vals, N_vals = spectral_counting(eigvals)\n",
    "    # restrict to lam <= lambda_max\n",
    "    mask_total = lam_vals <= lambda_max\n",
    "    lam_sel = lam_vals[mask_total]\n",
    "    N_sel = N_vals[mask_total]\n",
    "    n_lambda_total = len(lam_sel)\n",
    "    for k in k_values:\n",
    "        # drop k smallest lambda from lam_sel\n",
    "        if n_lambda_total - k < min_points_for_fit:\n",
    "            # insufficient points after dropping\n",
    "            rows.append({'b': b, 'levina_mle': levina_val, 'k': k, 'n_lambda_total': n_lambda_total, 'n_points_fit': max(0, n_lambda_total - k), 'theilsen_slope': np.nan, 'theilsen_d_s': np.nan, 'fit_ok': False})\n",
    "            continue\n",
    "        lam_k = lam_sel[k:]\n",
    "        N_k = N_sel[k:]\n",
    "        slope_k = theilsen_on_loglog(lam_k, N_k)\n",
    "        d_s_k = 2.0 * slope_k if not np.isnan(slope_k) else np.nan\n",
    "        rows.append({'b': b, 'levina_mle': levina_val, 'k': k, 'n_lambda_total': n_lambda_total, 'n_points_fit': len(lam_k), 'theilsen_slope': slope_k, 'theilsen_d_s': d_s_k, 'fit_ok': True})\n",
    "    print(f\"b={b}: lam_total={n_lambda_total}\")\n",
    "\n",
    "df_out = pd.DataFrame(rows)\n",
    "out_fp = os.path.join(out_dir, 'theilsen_ds_remove_small_lambda_per_b.csv')\n",
    "df_out.to_csv(out_fp, index=False)\n",
    "print(\"Saved per-b results to\", out_fp)\n",
    "\n",
    "# Pivot to wide form per b for quick comparisons (d_s_k0, d_s_k1, ...)\n",
    "pivot = df_out.pivot(index='b', columns='k', values='theilsen_d_s').rename(columns=lambda x: f\"d_s_k{x}\")\n",
    "pivot = pivot.reset_index()\n",
    "merged = pivot.merge(lev_df[['b','levina_mle']], on='b', how='left')\n",
    "merged_fp = os.path.join(out_dir, 'theilsen_ds_remove_small_lambda_wide.csv')\n",
    "merged.to_csv(merged_fp, index=False)\n",
    "print(\"Saved wide table to\", merged_fp)\n",
    "\n",
    "# Compute sensitivity (delta between k=0 and k=1) and flag sensitive bootstraps\n",
    "if ('d_s_k0' in merged.columns) and ('d_s_k1' in merged.columns):\n",
    "    merged['delta_k0_k1'] = merged['d_s_k1'] - merged['d_s_k0']\n",
    "    merged['abs_delta_k0_k1'] = np.abs(merged['delta_k0_k1'])\n",
    "    merged['sensitive_k0_k1'] = merged['abs_delta_k0_k1'] > sensitive_delta\n",
    "else:\n",
    "    merged['delta_k0_k1'] = np.nan\n",
    "    merged['abs_delta_k0_k1'] = np.nan\n",
    "    merged['sensitive_k0_k1'] = False\n",
    "\n",
    "merged.to_csv(os.path.join(out_dir, 'theilsen_ds_remove_small_lambda_wide_with_sensitivity.csv'), index=False)\n",
    "\n",
    "# Aggregate plot: median d_s vs k with IQR\n",
    "agg = df_out[df_out['fit_ok']].groupby('k')['theilsen_d_s'].agg(['median', lambda x: np.percentile(x,25), lambda x: np.percentile(x,75), 'count']).reset_index()\n",
    "agg.columns = ['k','median','q1','q3','n']\n",
    "plt.figure(figsize=(6,3.5))\n",
    "plt.plot(agg['k'], agg['median'], marker='o', label='median d_s')\n",
    "plt.fill_between(agg['k'], agg['q1'], agg['q3'], alpha=0.3, label='IQR')\n",
    "plt.xticks(k_values)\n",
    "plt.xlabel('k (number of smallest lambda excluded)')\n",
    "plt.ylabel('d_s = 2 * Theil-Sen slope')\n",
    "plt.title(f'd_s vs k (lambda_max={lambda_max})')\n",
    "plt.grid(alpha=0.25)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, 'ds_vs_k_plot.png'), dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved plot:\", os.path.join(out_dir, 'ds_vs_k_plot.png'))\n",
    "\n",
    "# Report summary of sensitivity\n",
    "sensitive_list = merged[merged['sensitive_k0_k1']].sort_values('abs_delta_k0_k1', ascending=False)\n",
    "sensitive_fp = os.path.join(out_dir, 'sensitive_bootstraps_k0_k1.csv')\n",
    "sensitive_list.to_csv(sensitive_fp, index=False)\n",
    "print(f\"Found {len(sensitive_list)} bootstraps with |d_s(k=1)-d_s(k=0)| > {sensitive_delta}; saved to\", sensitive_fp)\n",
    "\n",
    "print(\"Done. Files in\", out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0d126",
   "metadata": {},
   "source": [
    "### Résumé des fichiers\n",
    "- En supprimant les plus petites valeurs de lambda, le d_s dérivé par Theil–Sen augmente systématiquement sur les réplicats bootstrap : médiane d_s pour k=0 ≈ **1,56**, k=1 ≈ **1,71**, k=2 ≈ **1,79**, k=3 ≈ **1,87**.  \n",
    "- La courbe tracée et la bande IQR confirment le CSV : d_s croît de manière monotone avec k et l’écart interquartile s’élargit légèrement quand k augmente.  \n",
    "- Aucun replicate bootstrap n’affiche un changement absolu |d_s(k=1) − d_s(k=0)| > 0,2 (le fichier sensitive_bootstraps_k0_k1.csv est vide), donc la montée pour k=1 est systématique mais pas due à quelques bootstraps très sensibles.\n",
    "\n",
    "---\n",
    "\n",
    "### Chiffres et motifs clés\n",
    "- Médianes représentatives : **d_s(k=0) ≈ 1,56 → d_s(k=1) ≈ 1,71 → d_s(k=2) ≈ 1,79 → d_s(k=3) ≈ 1,87**.  \n",
    "- Quelques b montrent des augmentations plus marquées ; exemples notables dans le tableau large : **b=8** (d_s_k3 ≈ 2,00) ; **b=69** et **b=71** proches de 2,0.  \n",
    "- Les diagnostics par diag indiquent des ajustements valides (fit_ok=True) avec n_lambda_total typiques ≈ 16–18 ; Theil–Sen et d_s sont fournis pour chaque k.\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation courte\n",
    "- Les plus petites valeurs de lambda tirent la pente robuste vers le bas. Les supprimer (même k=1) augmente l’estimation robuste du taux (d_s), ce qui indique que les points à très petites lambda biaisent la pente à la baisse.  \n",
    "- L’augmentation est récurrente sur les bootstrap et n’est pas expliquée par quelques réplicats extrêmes.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48bc5697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results dir: C:\\Users\\zackd\\OneDrive\\Desktop\\Pipeline_Tlog_V0.1_Sunspots_En\\results\\ds_remove_small_lambda\n",
      "theilsen_ds_remove_small_lambda_wide.csv -> OK\n",
      "theilsen_ds_remove_small_lambda_per_b.csv -> OK\n",
      "\n",
      "Wide head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d_s_k0</th>\n",
       "      <th>d_s_k1</th>\n",
       "      <th>d_s_k2</th>\n",
       "      <th>d_s_k3</th>\n",
       "      <th>levina_mle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.624974</td>\n",
       "      <td>1.757424</td>\n",
       "      <td>1.836924</td>\n",
       "      <td>1.884547</td>\n",
       "      <td>7.857044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.556084</td>\n",
       "      <td>1.665759</td>\n",
       "      <td>1.786028</td>\n",
       "      <td>1.879125</td>\n",
       "      <td>7.934001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.550854</td>\n",
       "      <td>1.696551</td>\n",
       "      <td>1.801498</td>\n",
       "      <td>1.870492</td>\n",
       "      <td>7.909685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.554466</td>\n",
       "      <td>1.692034</td>\n",
       "      <td>1.758772</td>\n",
       "      <td>1.826618</td>\n",
       "      <td>7.854210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.594844</td>\n",
       "      <td>1.749521</td>\n",
       "      <td>1.807058</td>\n",
       "      <td>1.886138</td>\n",
       "      <td>7.885970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.530114</td>\n",
       "      <td>1.690646</td>\n",
       "      <td>1.779937</td>\n",
       "      <td>1.853736</td>\n",
       "      <td>7.897869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b    d_s_k0    d_s_k1    d_s_k2    d_s_k3  levina_mle\n",
       "0  1  1.624974  1.757424  1.836924  1.884547    7.857044\n",
       "1  2  1.556084  1.665759  1.786028  1.879125    7.934001\n",
       "2  3  1.550854  1.696551  1.801498  1.870492    7.909685\n",
       "3  4  1.554466  1.692034  1.758772  1.826618    7.854210\n",
       "4  5  1.594844  1.749521  1.807058  1.886138    7.885970\n",
       "5  6  1.530114  1.690646  1.779937  1.853736    7.897869"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median d_s_k0: 1.556  IQR: [1.506, 1.612]\n",
      "Median d_s_k1: 1.686  IQR: [1.634, 1.724]\n",
      "Median d_s_k2: 1.773  IQR: [1.737, 1.820]\n",
      "Median d_s_k3: 1.856  IQR: [1.811, 1.894]\n",
      "\n",
      "Top 6 par delta_k3_k0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d_s_k0</th>\n",
       "      <th>d_s_k1</th>\n",
       "      <th>d_s_k2</th>\n",
       "      <th>d_s_k3</th>\n",
       "      <th>levina_mle</th>\n",
       "      <th>delta_k3_k0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>1.381040</td>\n",
       "      <td>1.546471</td>\n",
       "      <td>1.670851</td>\n",
       "      <td>1.817115</td>\n",
       "      <td>8.032576</td>\n",
       "      <td>0.436074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>1.499975</td>\n",
       "      <td>1.647914</td>\n",
       "      <td>1.765159</td>\n",
       "      <td>1.910479</td>\n",
       "      <td>7.957769</td>\n",
       "      <td>0.410504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.506581</td>\n",
       "      <td>1.673304</td>\n",
       "      <td>1.784939</td>\n",
       "      <td>1.915532</td>\n",
       "      <td>7.986160</td>\n",
       "      <td>0.408952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>1.529791</td>\n",
       "      <td>1.653485</td>\n",
       "      <td>1.763305</td>\n",
       "      <td>1.933039</td>\n",
       "      <td>7.897929</td>\n",
       "      <td>0.403248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>1.459067</td>\n",
       "      <td>1.629828</td>\n",
       "      <td>1.765924</td>\n",
       "      <td>1.850124</td>\n",
       "      <td>7.923252</td>\n",
       "      <td>0.391057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>1.548615</td>\n",
       "      <td>1.711756</td>\n",
       "      <td>1.856505</td>\n",
       "      <td>1.934808</td>\n",
       "      <td>8.016001</td>\n",
       "      <td>0.386193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       b    d_s_k0    d_s_k1    d_s_k2    d_s_k3  levina_mle  delta_k3_k0\n",
       "139  140  1.381040  1.546471  1.670851  1.817115    8.032576     0.436074\n",
       "80    81  1.499975  1.647914  1.765159  1.910479    7.957769     0.410504\n",
       "16    17  1.506581  1.673304  1.784939  1.915532    7.986160     0.408952\n",
       "100  101  1.529791  1.653485  1.763305  1.933039    7.897929     0.403248\n",
       "55    56  1.459067  1.629828  1.765924  1.850124    7.923252     0.391057\n",
       "114  115  1.548615  1.711756  1.856505  1.934808    8.016001     0.386193"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6 centrés (quantile 50 ± quelques):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d_s_k0</th>\n",
       "      <th>d_s_k1</th>\n",
       "      <th>d_s_k2</th>\n",
       "      <th>d_s_k3</th>\n",
       "      <th>levina_mle</th>\n",
       "      <th>delta_k3_k0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.545257</td>\n",
       "      <td>1.628094</td>\n",
       "      <td>1.759671</td>\n",
       "      <td>1.837091</td>\n",
       "      <td>7.976557</td>\n",
       "      <td>0.291834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>1.535208</td>\n",
       "      <td>1.653949</td>\n",
       "      <td>1.744040</td>\n",
       "      <td>1.827399</td>\n",
       "      <td>8.010003</td>\n",
       "      <td>0.292191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1.450347</td>\n",
       "      <td>1.586596</td>\n",
       "      <td>1.683247</td>\n",
       "      <td>1.742162</td>\n",
       "      <td>8.007721</td>\n",
       "      <td>0.291815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.594844</td>\n",
       "      <td>1.749521</td>\n",
       "      <td>1.807058</td>\n",
       "      <td>1.886138</td>\n",
       "      <td>7.885970</td>\n",
       "      <td>0.291294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>1.609403</td>\n",
       "      <td>1.743389</td>\n",
       "      <td>1.833368</td>\n",
       "      <td>1.902580</td>\n",
       "      <td>7.898911</td>\n",
       "      <td>0.293177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>1.516873</td>\n",
       "      <td>1.658668</td>\n",
       "      <td>1.746048</td>\n",
       "      <td>1.807165</td>\n",
       "      <td>7.935097</td>\n",
       "      <td>0.290292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       b    d_s_k0    d_s_k1    d_s_k2    d_s_k3  levina_mle  delta_k3_k0\n",
       "23    24  1.545257  1.628094  1.759671  1.837091    7.976557     0.291834\n",
       "79    80  1.535208  1.653949  1.744040  1.827399    8.010003     0.292191\n",
       "25    26  1.450347  1.586596  1.683247  1.742162    8.007721     0.291815\n",
       "4      5  1.594844  1.749521  1.807058  1.886138    7.885970     0.291294\n",
       "135  136  1.609403  1.743389  1.833368  1.902580    7.898911     0.293177\n",
       "133  134  1.516873  1.658668  1.746048  1.807165    7.935097     0.290292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bottom 6 par delta_k3_k0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d_s_k0</th>\n",
       "      <th>d_s_k1</th>\n",
       "      <th>d_s_k2</th>\n",
       "      <th>d_s_k3</th>\n",
       "      <th>levina_mle</th>\n",
       "      <th>delta_k3_k0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.651128</td>\n",
       "      <td>1.723898</td>\n",
       "      <td>1.770994</td>\n",
       "      <td>1.831999</td>\n",
       "      <td>7.936887</td>\n",
       "      <td>0.180871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1.592740</td>\n",
       "      <td>1.674745</td>\n",
       "      <td>1.713255</td>\n",
       "      <td>1.784215</td>\n",
       "      <td>7.861878</td>\n",
       "      <td>0.191475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>1.715641</td>\n",
       "      <td>1.806167</td>\n",
       "      <td>1.882931</td>\n",
       "      <td>1.933152</td>\n",
       "      <td>7.941235</td>\n",
       "      <td>0.217511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1.601860</td>\n",
       "      <td>1.694923</td>\n",
       "      <td>1.775186</td>\n",
       "      <td>1.824429</td>\n",
       "      <td>8.064445</td>\n",
       "      <td>0.222569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>1.658420</td>\n",
       "      <td>1.733897</td>\n",
       "      <td>1.816615</td>\n",
       "      <td>1.881366</td>\n",
       "      <td>7.998421</td>\n",
       "      <td>0.222947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142</td>\n",
       "      <td>1.614789</td>\n",
       "      <td>1.694870</td>\n",
       "      <td>1.771746</td>\n",
       "      <td>1.838282</td>\n",
       "      <td>8.084957</td>\n",
       "      <td>0.223493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       b    d_s_k0    d_s_k1    d_s_k2    d_s_k3  levina_mle  delta_k3_k0\n",
       "6      7  1.651128  1.723898  1.770994  1.831999    7.936887     0.180871\n",
       "28    29  1.592740  1.674745  1.713255  1.784215    7.861878     0.191475\n",
       "88    89  1.715641  1.806167  1.882931  1.933152    7.941235     0.217511\n",
       "29    30  1.601860  1.694923  1.775186  1.824429    8.064445     0.222569\n",
       "48    49  1.658420  1.733897  1.816615  1.881366    7.998421     0.222947\n",
       "141  142  1.614789  1.694870  1.771746  1.838282    8.084957     0.223493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-b sample (head):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>levina_mle</th>\n",
       "      <th>k</th>\n",
       "      <th>n_lambda_total</th>\n",
       "      <th>n_points_fit</th>\n",
       "      <th>theilsen_slope</th>\n",
       "      <th>theilsen_d_s</th>\n",
       "      <th>fit_ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.857044</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.812487</td>\n",
       "      <td>1.624974</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.857044</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0.878712</td>\n",
       "      <td>1.757424</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7.857044</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0.918462</td>\n",
       "      <td>1.836924</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.857044</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0.942273</td>\n",
       "      <td>1.884547</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7.934001</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.778042</td>\n",
       "      <td>1.556084</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>7.934001</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0.832879</td>\n",
       "      <td>1.665759</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b  levina_mle  k  n_lambda_total  n_points_fit  theilsen_slope  \\\n",
       "0  1    7.857044  0              17            17        0.812487   \n",
       "1  1    7.857044  1              17            16        0.878712   \n",
       "2  1    7.857044  2              17            15        0.918462   \n",
       "3  1    7.857044  3              17            14        0.942273   \n",
       "4  2    7.934001  0              17            17        0.778042   \n",
       "5  2    7.934001  1              17            16        0.832879   \n",
       "\n",
       "   theilsen_d_s  fit_ok  \n",
       "0      1.624974    True  \n",
       "1      1.757424    True  \n",
       "2      1.836924    True  \n",
       "3      1.884547    True  \n",
       "4      1.556084    True  \n",
       "5      1.665759    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution n_points_fit:\n",
      "count    600.000000\n",
      "mean      14.960000\n",
      "std        1.283672\n",
      "min       12.000000\n",
      "25%       14.000000\n",
      "50%       15.000000\n",
      "75%       16.000000\n",
      "max       18.000000\n",
      "Name: n_points_fit, dtype: float64\n",
      "\n",
      "Top5 selected for diagnostics: [140, 81, 17, 101, 56]\n",
      "Aucun fichier paired trouvé dans results ; j'essaierai d'utiliser per-b pour tracer quand possible.\n",
      "Saved diagnostics_theilsen_per_b\\b_140_diagnostic.png\n",
      "Saved diagnostics_theilsen_per_b\\b_81_diagnostic.png\n",
      "Saved diagnostics_theilsen_per_b\\b_17_diagnostic.png\n",
      "Saved diagnostics_theilsen_per_b\\b_101_diagnostic.png\n",
      "Saved diagnostics_theilsen_per_b\\b_56_diagnostic.png\n",
      "\n",
      "Manifest written: results\\ds_remove_small_lambda\\manifest_from_inspect.json\n",
      "Diagnostics saved in C:\\Users\\zackd\\OneDrive\\Desktop\\Pipeline_Tlog_V0.1_Sunspots_En\\diagnostics_theilsen_per_b\n"
     ]
    }
   ],
   "source": [
    "# Cellule : inspection et régénération contrôlée depuis results/ds_remove_small_lambda\n",
    "import hashlib, json, math, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"font.size\":10})\n",
    "\n",
    "# Ajuster si besoin : chemin du dossier produit par ton pipeline\n",
    "results_dir = Path(\"results/ds_remove_small_lambda\")\n",
    "if not results_dir.exists():\n",
    "    raise FileNotFoundError(f\"Répertoire introuvable : {results_dir.resolve()}\")\n",
    "\n",
    "print(\"Results dir:\", results_dir.resolve())\n",
    "\n",
    "# Fichiers attendus\n",
    "wide_fp = results_dir / \"theilsen_ds_remove_small_lambda_wide.csv\"\n",
    "perb_fp = results_dir / \"theilsen_ds_remove_small_lambda_per_b.csv\"\n",
    "perb_all_fp = results_dir / \"theilsen_ds_remove_small_lambda_per_b.csv\"  # fallback same name\n",
    "\n",
    "# Vérification existence\n",
    "for p in (wide_fp, perb_fp):\n",
    "    print(p.name, \"->\", \"OK\" if p.exists() else \"MISSING\")\n",
    "\n",
    "# Charger si disponibles\n",
    "wide = pd.read_csv(wide_fp) if wide_fp.exists() else None\n",
    "perb = pd.read_csv(perb_fp) if perb_fp.exists() else None\n",
    "\n",
    "# Résumé wide\n",
    "if wide is None:\n",
    "    raise RuntimeError(\"Fichier wide manquant : impossible d'aller plus loin.\")\n",
    "print(\"\\nWide head:\")\n",
    "display(wide.head(6))\n",
    "\n",
    "# Calculs agrégés\n",
    "for k in [0,1,2,3]:\n",
    "    col = f\"d_s_k{k}\"\n",
    "    if col in wide.columns:\n",
    "        med = wide[col].median()\n",
    "        q1 = wide[col].quantile(0.25)\n",
    "        q3 = wide[col].quantile(0.75)\n",
    "        print(f\"Median {col}: {med:.3f}  IQR: [{q1:.3f}, {q3:.3f}]\")\n",
    "    else:\n",
    "        print(f\"Colonne manquante: {col}\")\n",
    "\n",
    "# Top / median / bottom examples\n",
    "wide = wide.copy()\n",
    "wide[\"delta_k3_k0\"] = wide.get(\"d_s_k3\", np.nan) - wide.get(\"d_s_k0\", np.nan)\n",
    "print(\"\\nTop 6 par delta_k3_k0:\")\n",
    "display(wide.sort_values(\"delta_k3_k0\", ascending=False).head(6))\n",
    "print(\"\\n6 centrés (quantile 50 ± quelques):\")\n",
    "m = wide[\"delta_k3_k0\"].median()\n",
    "display(wide.iloc[(wide[\"delta_k3_k0\"]-m).abs().argsort()[:6]])\n",
    "print(\"\\nBottom 6 par delta_k3_k0:\")\n",
    "display(wide.sort_values(\"delta_k3_k0\", ascending=True).head(6))\n",
    "\n",
    "# Résumé per-b\n",
    "if perb is not None:\n",
    "    print(\"\\nPer-b sample (head):\")\n",
    "    display(perb.head(6))\n",
    "    print(\"Distribution n_points_fit:\")\n",
    "    if \"n_points_fit\" in perb.columns:\n",
    "        print(perb[\"n_points_fit\"].describe())\n",
    "    else:\n",
    "        print(\"colonne n_points_fit absente\")\n",
    "else:\n",
    "    print(\"per-b absent ; continuer avec wide uniquement\")\n",
    "\n",
    "# Créer dossier de diagnostics (local)\n",
    "out_dir = Path(\"diagnostics_theilsen_per_b\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Choisir top5 b par delta_k3_k0 (fallback à d_s_k3/d_s_k0 s'ils existent)\n",
    "top5 = wide.sort_values(\"delta_k3_k0\", ascending=False).head(5)[\"b\"].astype(int).tolist()\n",
    "print(\"\\nTop5 selected for diagnostics:\", top5)\n",
    "\n",
    "# Charger paired data si existant dans results (essentiel pour tracer N(lambda) vs lambda)\n",
    "# On va essayer d'extraire les N(lambda) observés depuis perb: perb contient lignes (b,k,lambda info)\n",
    "# Si tu as un CSV 'paired_levina_spectral_theilsen_raw.csv' dans results, priorise-le\n",
    "paired_fp_candidates = list(results_dir.glob(\"paired*.csv\")) + list(results_dir.glob(\"*paired*.csv\"))\n",
    "if paired_fp_candidates:\n",
    "    paired_fp = paired_fp_candidates[0]\n",
    "    paired = pd.read_csv(paired_fp)\n",
    "    print(\"Paired file used:\", paired_fp.name)\n",
    "else:\n",
    "    # fallback: try to reconstruct from perb rows aggregated by lambda_max (if available)\n",
    "    paired = None\n",
    "    print(\"Aucun fichier paired trouvé dans results ; j'essaierai d'utiliser per-b pour tracer quand possible.\")\n",
    "\n",
    "# helper to compute slope intercept from perb or wide\n",
    "def get_slopes_for_b(b_val):\n",
    "    slopes = {}\n",
    "    if perb is not None and \"k\" in perb.columns:\n",
    "        for k in [0,1,2,3]:\n",
    "            row = perb[(perb[\"b\"]==int(b_val)) & (perb[\"k\"]==k)]\n",
    "            if len(row)>0:\n",
    "                if \"theilsen_slope\" in row.columns:\n",
    "                    slopes[k] = float(row[\"theilsen_slope\"].iloc[0])\n",
    "                elif \"theilsen_d_s\" in row.columns:\n",
    "                    slopes[k] = float(row[\"theilsen_d_s\"].iloc[0]) / 2.0\n",
    "                else:\n",
    "                    slopes[k] = None\n",
    "            else:\n",
    "                slopes[k] = None\n",
    "    else:\n",
    "        # fallback to wide\n",
    "        wrow = wide[wide[\"b\"]==int(b_val)]\n",
    "        if not wrow.empty:\n",
    "            for k in [0,1,2,3]:\n",
    "                col = f\"d_s_k{k}\"\n",
    "                slopes[k] = (float(wrow[col].iloc[0]) / 2.0) if col in wrow.columns else None\n",
    "        else:\n",
    "            slopes = {0:None,1:None,2:None,3:None}\n",
    "    return slopes\n",
    "\n",
    "# Fonction de tracé si on a paired, sinon trace approximative en utilisant n_points_fit par lambda_max\n",
    "def plot_b(b_val):\n",
    "    slopes = get_slopes_for_b(b_val)\n",
    "    if paired is not None:\n",
    "        df_b = paired[paired[\"b\"]==int(b_val)].sort_values(\"lambda_max\")\n",
    "        lam = df_b[\"lambda_max\"].astype(float).values\n",
    "        N_obs = df_b[\"n_points_fit\"].astype(float).values\n",
    "    else:\n",
    "        # tenter d'extraire lam/N depuis perb rows (si elles contiennent lambda_max & N info)\n",
    "        df_b = perb[perb[\"b\"]==int(b_val)].sort_values(\"k\") if perb is not None else None\n",
    "        if df_b is None or df_b.empty or \"n_lambda_total\" not in df_b.columns:\n",
    "            print(f\"Impossible de tracer b={b_val} : manque paired ou champs N(lambda).\")\n",
    "            return\n",
    "        # approximate: use unique lambda_max values present in perb (if available)\n",
    "        lam = df_b[\"n_lambda_total\"].astype(float).values  # fallback nonsense but avoid crash\n",
    "        N_obs = np.arange(1, len(lam)+1)\n",
    "    # compute intercepts from first valid point\n",
    "    intercepts = {}\n",
    "    for k,slope in slopes.items():\n",
    "        if slope is None:\n",
    "            intercepts[k] = None\n",
    "            continue\n",
    "        idx = np.where(N_obs>0)[0]\n",
    "        if len(idx)==0:\n",
    "            intercepts[k] = None\n",
    "            continue\n",
    "        i0 = idx[0]\n",
    "        intercepts[k] = math.log(N_obs[i0]) - slope * math.log(lam[i0])\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    ax.scatter(lam, N_obs, c='k', s=50, label='N(lambda) observé')\n",
    "    ax.set_xscale('log'); ax.set_yscale('log')\n",
    "    colors = {0:'#1f77b4',1:'#ff7f0e',2:'#2ca02c',3:'#d62728'}\n",
    "    for k in [0,1,2,3]:\n",
    "        s = slopes.get(k)\n",
    "        inter = intercepts.get(k)\n",
    "        if s is None or inter is None:\n",
    "            continue\n",
    "        lamr = np.logspace(np.log10(min(lam)) - 0.05, np.log10(max(lam)) + 0.05, 200)\n",
    "        Nline = np.exp(inter + s * np.log(lamr))\n",
    "        ax.plot(lamr, Nline, color=colors[k], lw=2, label=f'k={k} slope={s:.3f} d_s={2*s:.3f}')\n",
    "    ax.set_xlabel('lambda (log)')\n",
    "    ax.set_ylabel('N(lambda) (log)')\n",
    "    ax.set_title(f'b={b_val} diagnostic')\n",
    "    ax.legend(fontsize=9)\n",
    "    outp = out_dir / f\"b_{b_val}_diagnostic.png\"\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outp, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved\", outp)\n",
    "\n",
    "# Générer diagnostics pour top5\n",
    "for b in top5:\n",
    "    plot_b(b)\n",
    "\n",
    "# Ecrire manifeste minimal\n",
    "manifest = {\"results_dir\": str(results_dir.resolve()), \"generated_at\": pd.Timestamp.now().isoformat(), \"files\": {}}\n",
    "for f in results_dir.glob(\"*\"):\n",
    "    try:\n",
    "        stat = f.stat()\n",
    "        with f.open(\"rb\") as fh:\n",
    "            h = hashlib.sha1(fh.read()).hexdigest()\n",
    "        manifest[\"files\"][f.name] = {\"path\": str(f.resolve()), \"size\": stat.st_size, \"sha1\": h}\n",
    "    except Exception:\n",
    "        manifest[\"files\"][f.name] = {\"path\": str(f.resolve()), \"size\": None, \"sha1\": None}\n",
    "(manifest_fp := results_dir / \"manifest_from_inspect.json\").write_text(json.dumps(manifest, indent=2))\n",
    "print(\"\\nManifest written:\", manifest_fp)\n",
    "print(\"Diagnostics saved in\", out_dir.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN5vs3Hjg7uRmHLLvE8miZh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
