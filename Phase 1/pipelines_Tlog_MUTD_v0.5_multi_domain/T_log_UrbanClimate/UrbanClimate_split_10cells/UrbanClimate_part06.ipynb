{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc76d6c",
   "metadata": {
    "id": "K10nkix2tFDm"
   },
   "source": [
    "### Résumé prioritaire\n",
    "\n",
    "- Fenêtres signalées : 3yr_1984.0_{A,B,C}, 3yr_2014.0_{A,B,C}, annual_2003.0_{A,C}, annual_2008.0_{A,B,C}, annual_2012.0_{A,B,C}, annual_2014.0_{A,C}, annual_2016.0_{A,B,C}.  \n",
    "- Pattern commun : mêmes 5 features utilisées (temperature_celsius; humidity_percent; precipitation_mm; wind_speed_ms; urban_heat_island_intensity) et même ville signalée comme top offender : **Beijing_China_39.9042_116.4074**.  \n",
    "- Observations typiques : prop_obs_outlier ≈ 0.0257 (≈2.6%), median_md ≈ 3.0, prop_cities_with_gt10pct_outliers = 0.05, max_city_outlier_frac ∈ [0.486, 0.538] — une seule ville concentre une large part des outliers.  \n",
    "- Sensibilité : enlever la ville top‑offender provoque des deltas T_log notables (ex. −0.0786 pour 3yr_1984.0_A), donc la statistique globale est sensible à quelques villes.\n",
    "\n",
    "---\n",
    "\n",
    "### Chiffres clés à retenir\n",
    "\n",
    "- Median Mahalanobis (median_md) ≈ 3.0 pour fenêtres concernées.  \n",
    "- prop_obs_outlier ≈ 2.6% par fenêtre.  \n",
    "- T_log exemples : 3yr_1984.0_A T_log = 0.06899 ; 3yr_2014.0_A T_log = 0.05121 ; annual_2008.0_A T_log = 0.14551 ; global T_log (logs) = −0.298824 (régime Divergence).  \n",
    "- Transformations testées : winsor_precip, log1p_precip ; effets mesurés dans colonnes winsor_precip_T_log et log1p_precip_T_log du résumé.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee2b55",
   "metadata": {
    "id": "5Nz28uAHtpbd"
   },
   "source": [
    "\n",
    "\n",
    "### Vérifications immédiates (haut rendement / faible coût)\n",
    "\n",
    "1. Confirmer la contribution de Beijing : ouvrir diagnostics_by_city pour une fenêtre (ex. results/.../3yr_1984.0_A/diagnostics_by_city_3yr_1984.0_A.csv) et lire n_obs, moyennes, et compte outliers par feature pour Beijing.  \n",
    "2. Recalculer T_log en excluant Beijing pour une fenêtre représentative et mesurer delta_T_log_exclude_topcity. Si |delta| > 0.02, marquer comme haute sensibilité.  \n",
    "3. Comparer winsor_precip_T_log vs log1p_precip_T_log dans tests_priority_summary.csv ; prioriser fenêtres où la transformation change fortement T_log.  \n",
    "4. Vérifier dans summary_* quels features génèrent le plus d’outliers (precipitation_mm et urban_heat_island_intensity apparaissent souvent).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42945c9c",
   "metadata": {
    "id": "QG26u0zWt4Ve"
   },
   "source": [
    "Commandes rapides utiles\n",
    "\n",
    "Lister les fenêtres les plus sensibles (par |delta_T_log_exclude_topcity|) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "047a36bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1761435168424,
     "user": {
      "displayName": "GlobalZivotPrint",
      "userId": "12055292741917834281"
     },
     "user_tz": 240
    },
    "id": "zprEWUVGt6Wt",
    "outputId": "3e0a7561-68e4-4340-cd86-094f8ee6f2e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>window_center</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>T_log</th>\n",
       "      <th>exclude_topcity_T_log</th>\n",
       "      <th>delta_T_log_exclude_topcity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>annual_2012.0_C</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.052576</td>\n",
       "      <td>-0.147700</td>\n",
       "      <td>-0.200276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>annual_2012.0_B</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.052576</td>\n",
       "      <td>-0.147700</td>\n",
       "      <td>-0.200276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>annual_2012.0_A</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.052576</td>\n",
       "      <td>-0.147700</td>\n",
       "      <td>-0.200276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>annual_2008.0_B</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.145512</td>\n",
       "      <td>0.052835</td>\n",
       "      <td>-0.092677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>annual_2008.0_A</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.145512</td>\n",
       "      <td>0.052835</td>\n",
       "      <td>-0.092677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>annual_2008.0_C</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.145512</td>\n",
       "      <td>0.052835</td>\n",
       "      <td>-0.092677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3yr_1984.0_B</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>-0.009656</td>\n",
       "      <td>-0.078643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3yr_1984.0_A</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>-0.009656</td>\n",
       "      <td>-0.078643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3yr_1984.0_C</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>-0.009656</td>\n",
       "      <td>-0.078643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>annual_2016.0_A</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.029690</td>\n",
       "      <td>-0.023059</td>\n",
       "      <td>-0.052749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tag  window_center pipeline     T_log  exclude_topcity_T_log  \\\n",
       "13  annual_2012.0_C         2012.0        C  0.052576              -0.147700   \n",
       "12  annual_2012.0_B         2012.0        B  0.052576              -0.147700   \n",
       "11  annual_2012.0_A         2012.0        A  0.052576              -0.147700   \n",
       "9   annual_2008.0_B         2008.0        B  0.145512               0.052835   \n",
       "8   annual_2008.0_A         2008.0        A  0.145512               0.052835   \n",
       "10  annual_2008.0_C         2008.0        C  0.145512               0.052835   \n",
       "1      3yr_1984.0_B         1984.0        B  0.068987              -0.009656   \n",
       "0      3yr_1984.0_A         1984.0        A  0.068987              -0.009656   \n",
       "2      3yr_1984.0_C         1984.0        C  0.068987              -0.009656   \n",
       "16  annual_2016.0_A         2016.0        A  0.029690              -0.023059   \n",
       "\n",
       "    delta_T_log_exclude_topcity  \n",
       "13                    -0.200276  \n",
       "12                    -0.200276  \n",
       "11                    -0.200276  \n",
       "9                     -0.092677  \n",
       "8                     -0.092677  \n",
       "10                    -0.092677  \n",
       "1                     -0.078643  \n",
       "0                     -0.078643  \n",
       "2                     -0.078643  \n",
       "16                    -0.052749  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results/temporal_cv_atypical_windows/diagnostics/tests_priority_summary.csv\")\n",
    "df['delta_abs'] = df['delta_T_log_exclude_topcity'].abs()\n",
    "df.sort_values('delta_abs', ascending=False).head(10)[['tag','window_center','pipeline','T_log','exclude_topcity_T_log','delta_T_log_exclude_topcity']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92692ba",
   "metadata": {
    "id": "nI-4dAtQt9iW"
   },
   "source": [
    "Recalculer T_log sans Beijing (pseudo) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24a63364",
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1761435185947,
     "user": {
      "displayName": "GlobalZivotPrint",
      "userId": "12055292741917834281"
     },
     "user_tz": 240
    },
    "id": "7tODkrAtt-x2"
   },
   "outputs": [],
   "source": [
    "w = \"results/temporal_cv_atypical_windows/temporal_cv_atypical_period_window_3yr_1984.00_A_raw.csv\"\n",
    "dfw = pd.read_csv(w)\n",
    "df_no_beijing = dfw[dfw['city_key'] != \"Beijing_China_39.9042_116.4074\"]\n",
    "# Agréger par city_key, standardiser, calculer d_part/d_pca90 comme dans votre routine, puis T_log = (d_est-4)*ln(n_eff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37208b14",
   "metadata": {
    "id": "f0QuHeQguzLR"
   },
   "source": [
    "Cellule Python automatisée — recalculer T_log sans la ville spécifiée (batch)\n",
    "\n",
    " La cellule :\n",
    "\n",
    "lit tests_priority_summary.csv et sélectionne les fenêtres à traiter (par défaut top 10 par |delta_T_log_exclude_topcity|) ;\n",
    "\n",
    "pour chaque fenêtre : charge le raw CSV listé dans l’index enrichi, agrège par city_key (moyennes temporelles), standardise, calcule d_part, d_pca90, d_est et T_log original et T_log recalculé en excluant la ville top_offender ;\n",
    "\n",
    "sauvegarde un CSV résumé comparatif et pour chaque fenêtre un petit dossier contenant plots (heatmap per-city×feature medians, timeseries du top_city pour precipitation_mm si présente) ;\n",
    "\n",
    "paramètres configurables en haut de la cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "234fc600",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14734,
     "status": "ok",
     "timestamp": 1761435443366,
     "user": {
      "displayName": "GlobalZivotPrint",
      "userId": "12055292741917834281"
     },
     "user_tz": 240
    },
    "id": "4lyP8Wwau57Y",
    "outputId": "3b34e633-3a93-4a07-e4c9-858e71ae56a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats écrits : results/temporal_cv_atypical_windows/diagnostics/tlog_exclude_city_results\\tlog_exclude_topcity_comparison.csv\n",
      "Plots par fenêtre sous : results/temporal_cv_atypical_windows/diagnostics/tlog_exclude_city_results\n"
     ]
    }
   ],
   "source": [
    "# Cellule : recalcul automatique T_log sans la ville top_offender (batch)\n",
    "import os, re, math, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Configurable\n",
    "IDX_ENR = 'results/temporal_cv_atypical_windows/temporal_cv_atypical_periods_windows_index_enriched.csv'\n",
    "PRIO_SUM = 'results/temporal_cv_atypical_windows/diagnostics/tests_priority_summary.csv'\n",
    "OUT_DIR = 'results/temporal_cv_atypical_windows/diagnostics/tlog_exclude_city_results'\n",
    "TOPN = 10               # nombre de fenêtres à traiter (par delta absolu)\n",
    "DEFAULT_FEATURES = ['temperature_celsius','humidity_percent','precipitation_mm','wind_speed_ms','urban_heat_island_intensity']\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def safe_tag(s): return re.sub(r'[^0-9A-Za-z_.-]', '_', str(s))\n",
    "\n",
    "def compute_d_estimate_from_X(X):\n",
    "    # X : (cities x features) already standardized float ndarray\n",
    "    if X.shape[0] < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    cov = np.cov(X, rowvar=False)\n",
    "    eigvals = np.linalg.eigvalsh(cov)\n",
    "    eigvals = np.maximum(eigvals, 0.0)\n",
    "    sum_eig = np.sum(eigvals)\n",
    "    d_part = 0.0 if sum_eig <= 0 else (sum_eig**2) / np.sum(eigvals**2)\n",
    "    pca = PCA(n_components=min(X.shape[0], X.shape[1])).fit(X)\n",
    "    cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d_pca90 = int(np.searchsorted(cumvar, 0.90) + 1) if cumvar[-1] >= 0.90 else pca.n_components_\n",
    "    d_est = float((d_part + d_pca90) / 2.0)\n",
    "    return d_part, d_pca90, d_est\n",
    "\n",
    "def compute_T_log(d_est, n_eff):\n",
    "    n_eff = max(2, int(n_eff))\n",
    "    return (d_est - 4.0) * np.log(n_eff)\n",
    "\n",
    "# Load priority table (must exist)\n",
    "if not os.path.exists(PRIO_SUM):\n",
    "    raise FileNotFoundError(f\"Priority summary introuvable: {PRIO_SUM}\")\n",
    "\n",
    "prio = pd.read_csv(PRIO_SUM)\n",
    "# ensure delta exists\n",
    "if 'delta_T_log_exclude_topcity' not in prio.columns:\n",
    "    raise RuntimeError(\"Colonne delta_T_log_exclude_topcity absente du fichier priority summary\")\n",
    "\n",
    "# pick top windows by absolute delta (or all if fewer)\n",
    "prio['delta_abs'] = prio['delta_T_log_exclude_topcity'].abs().fillna(0.0)\n",
    "sel = prio.sort_values('delta_abs', ascending=False).head(TOPN)\n",
    "\n",
    "results = []\n",
    "for _, row in sel.iterrows():\n",
    "    tag = row['tag']\n",
    "    window_type = row.get('window_type')\n",
    "    window_center = row.get('window_center')\n",
    "    pipeline = row.get('pipeline')\n",
    "    raw_candidates = []\n",
    "    # try to find raw csv path: check index enriched first\n",
    "    if os.path.exists(IDX_ENR):\n",
    "        idx = pd.read_csv(IDX_ENR)\n",
    "        match = idx[(idx['window_type']==window_type) & (idx['window_center']==float(window_center)) & (idx['pipeline']==pipeline)]\n",
    "        if not match.empty and 'raw_csv' in match.columns:\n",
    "            raw_candidates.append(match.iloc[0]['raw_csv'])\n",
    "    # fallback heuristics\n",
    "    raw_candidates.extend(glob.glob(os.path.join('results','temporal_cv_atypical_windows',f'*{tag}*raw.csv')))\n",
    "    raw_fp = next((p for p in raw_candidates if p and os.path.exists(p)), None)\n",
    "    if raw_fp is None:\n",
    "        results.append({'tag': tag, 'status': 'no_raw_found'})\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(raw_fp)\n",
    "    if 'city_key' not in df.columns:\n",
    "        agg_cols = [c for c in ['city','country','latitude','longitude'] if c in df.columns]\n",
    "        df['city_key'] = df[agg_cols].astype(str).agg('_'.join, axis=1) if agg_cols else 'unknown'\n",
    "\n",
    "    # detect features to use\n",
    "    num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in ['year','month','n_rows']]\n",
    "    features = [c for c in DEFAULT_FEATURES if c in num_cols] or (num_cols[:min(5,len(num_cols))] if num_cols else [])\n",
    "    if not features:\n",
    "        results.append({'tag': tag, 'status': 'no_numeric_features'})\n",
    "        continue\n",
    "\n",
    "    # aggregate per-city (median or mean; use mean for consistency)\n",
    "    city_df = df.groupby('city_key')[features].mean().reset_index()\n",
    "    # drop cities with any NaN in the selected features\n",
    "    city_df_clean = city_df.dropna(subset=features).reset_index(drop=True)\n",
    "    n_cities = city_df_clean.shape[0]\n",
    "    if n_cities < 2:\n",
    "        results.append({'tag': tag, 'status': 'not_enough_cities', 'n_cities': n_cities})\n",
    "        continue\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(city_df_clean[features].astype(float).values)\n",
    "    d_part, d_pca90, d_est = compute_d_estimate_from_X(X)\n",
    "    T_log_orig = compute_T_log(d_est, X.shape[0])\n",
    "\n",
    "    top_city = row.get('top_city')\n",
    "    if not top_city or top_city not in city_df_clean['city_key'].values:\n",
    "        # try best-effort: pick city with max outlier fraction in per-city diagnostics if present\n",
    "        # fallback to city with largest n_obs in raw df\n",
    "        if 'city_key' in df.columns:\n",
    "            counts = df['city_key'].value_counts()\n",
    "            top_city = counts.index[0] if not counts.empty else None\n",
    "\n",
    "    # compute per-city medians matrix for heatmap\n",
    "    heatmap_mat = city_df_clean.set_index('city_key')[features]\n",
    "\n",
    "    # Recompute excluding top city if possible\n",
    "    exclude_T_log = np.nan\n",
    "    delta = np.nan\n",
    "    d_part_ex = d_pca90_ex = d_est_ex = np.nan\n",
    "    if top_city and top_city in city_df_clean['city_key'].values:\n",
    "        city_df_ex = city_df_clean[city_df_clean['city_key'] != top_city].reset_index(drop=True)\n",
    "        if city_df_ex.shape[0] >= 2:\n",
    "            Xex = scaler.fit_transform(city_df_ex[features].astype(float).values)\n",
    "            d_part_ex, d_pca90_ex, d_est_ex = compute_d_estimate_from_X(Xex)\n",
    "            exclude_T_log = compute_T_log(d_est_ex, Xex.shape[0])\n",
    "            delta = exclude_T_log - T_log_orig\n",
    "\n",
    "    # Save summary entry\n",
    "    res_row = {\n",
    "        'tag': tag, 'window_type': window_type, 'window_center': window_center, 'pipeline': pipeline,\n",
    "        'raw_csv': raw_fp, 'n_cities': n_cities, 'features': ';'.join(features),\n",
    "        'top_city': top_city, 'T_log_orig': float(T_log_orig), 'T_log_exclude_topcity': float(exclude_T_log) if not np.isnan(exclude_T_log) else np.nan,\n",
    "        'delta_T_log_exclude_topcity': float(delta) if not np.isnan(delta) else np.nan,\n",
    "        'd_part': float(d_part), 'd_pca90': int(d_pca90), 'd_est': float(d_est),\n",
    "        'd_part_ex': float(d_part_ex) if not np.isnan(d_part_ex) else np.nan,\n",
    "        'd_pca90_ex': int(d_pca90_ex) if not np.isnan(d_pca90_ex) else np.nan,\n",
    "        'd_est_ex': float(d_est_ex) if not np.isnan(d_est_ex) else np.nan,\n",
    "        'status': 'ok'\n",
    "    }\n",
    "    results.append(res_row)\n",
    "\n",
    "    # Plots folder for this window\n",
    "    fig_dir = os.path.join(OUT_DIR, safe_tag(tag))\n",
    "    os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # heatmap of city medians (z-scored per feature)\n",
    "        hm = heatmap_mat.copy().astype(float)\n",
    "        for col in hm.columns:\n",
    "            colv = hm[col]\n",
    "            if colv.dropna().shape[0] >= 2 and not np.isclose(colv.std(ddof=1), 0.0):\n",
    "                hm[col] = (colv - colv.mean()) / colv.std(ddof=1)\n",
    "            else:\n",
    "                mn = colv.min(); mx = colv.max()\n",
    "                hm[col] = 0 if np.isclose(mx, mn) else (colv - mn) / (mx - mn)\n",
    "        plt.figure(figsize=(8, max(4, min(30, hm.shape[0]*0.25))))\n",
    "        plt.imshow(hm.values, aspect='auto', cmap='vlag', interpolation='nearest')\n",
    "        plt.colorbar(label='normalized median')\n",
    "        plt.yticks(range(len(hm.index)), hm.index)\n",
    "        plt.xticks(range(len(hm.columns)), hm.columns, rotation=45, ha='right')\n",
    "        plt.title(f'Heatmap medians per city - {tag}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(fig_dir, f'{safe_tag(tag)}_heatmap.png'), dpi=150)\n",
    "        plt.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # top city timeseries for precipitation_mm if present\n",
    "        if 'precipitation_mm' in features and top_city in df['city_key'].unique():\n",
    "            df_city = df[df['city_key']==top_city].sort_index()\n",
    "            plt.figure(figsize=(8,2.5))\n",
    "            plt.plot(df_city['precipitation_mm'].values, marker='o', markersize=3, linestyle='-')\n",
    "            plt.title(f'{tag} - precipitation_mm timeseries - {top_city}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(fig_dir, f'{safe_tag(tag)}_topcity_precip_timeseries.png'), dpi=150)\n",
    "            plt.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Write results CSV\n",
    "out_csv = os.path.join(OUT_DIR, 'tlog_exclude_topcity_comparison.csv')\n",
    "pd.DataFrame(results).to_csv(out_csv, index=False)\n",
    "print(\"Résultats écrits :\", out_csv)\n",
    "print(\"Plots par fenêtre sous :\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2072eb4f",
   "metadata": {
    "id": "rHuzWEMnxY7s"
   },
   "source": [
    "### Résumé rapide des résultats (tlog_exclude_topcity_comparison.csv)\n",
    "\n",
    "- **Top city identifiée** : Beijing_China_39.9042_116.4074 pour toutes les fenêtres listées.  \n",
    "- **Effet d’exclusion** : pour chaque fenêtre, l’exclusion de la top city fait chuter T_log (delta_T_log_exclude_topcity < 0 dans tous les cas).  \n",
    "- **Amplitude de l’effet** : les baisses de T_log vont d’environ **-0.05** à **-0.20** (ex. annual_2012 Δ ≈ -0.20; annual_2008 Δ ≈ -0.093; 3yr_1984 Δ ≈ -0.079; annual_2016 Δ ≈ -0.053).  \n",
    "- **Impact sur l’estimation de dimension d** : la valeur finale d_est diminue légèrement après exclusion (typ. baisse de ~0.03–0.07), indiquant que la top city contribue à accroître l’estimation effective de la dimension.  \n",
    "- **Statut de ces lignes** : toutes marquées \"ok\".\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation actionable (conclusions directes)\n",
    "- Beijing exerce une influence positive sur T_log dans ces sous-ensembles; son retrait rend le diagnostic plus négatif (pousse vers la divergence).  \n",
    "- Les changements de d_est sont modestes mais cohérents : la présence de la top city augmente légèrement la complexité effective perçue du jeu de villes.  \n",
    "- L’effet n’est pas catastrophique (pas de renversement de signe massif sauf réduction notable), mais suffisamment large sur certaines fenêtres (ex. annual_2012) pour mériter investigation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Résumé court (une ligne)\n",
    "L’exclusion de Beijing rend systématiquement T_log plus négatif et réduit légèrement d_est ; Beijing est un contributeur structurant du signal dans ces fenêtres — action recommandée : quantifier l’influence LOO complète, décomposer par feature, et tester estimateurs plus robustes avant décision finale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc4cfd",
   "metadata": {
    "id": "bIaJZyZTyikt"
   },
   "source": [
    "Objectifs précis de l’exécution LOO étendue\n",
    "\n",
    "Pour chaque fenêtre flaggée, recalculer T_log en retirant chaque ville à tour de rôle.\n",
    "\n",
    "Produire un CSV résumé classant les villes par delta moyen (T_log_without_city − T_log_full), delta absolu, et nombre d’occasions où la suppression inverse le régime.\n",
    "\n",
    "Sauvegarder pour chaque fenêtre : top 5 villes influentes + un plot montrant la distribution LOO de T_log et la position du T_log complet.\n",
    "\n",
    "Résultat pratique : shortlist des villes à downweight/exclure/tester avec corrections de features.\n",
    "\n",
    "Cellule Python — LOO étendue, classement d’influence et plots\n",
    "\n",
    " Elle parcourt les fenêtres listées dans tests_priority_summary.csv (ou index enrichi), effectue LOO par ville, écrit un CSV classement et exporte plots par fenêtre."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMj8BTKhAxEVfHfc0L9NwkV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
